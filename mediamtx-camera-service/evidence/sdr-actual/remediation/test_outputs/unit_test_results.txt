============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.4.1, pluggy-1.6.0
rootdir: /home/dts/CameraRecorder/mediamtx-camera-service
configfile: pytest.ini
plugins: asyncio-1.1.0, cov-6.2.1, anyio-4.9.0
asyncio: mode=strict, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 322 items

tests/unit/test_camera_discovery/test_capability_detection.py .          [  0%]
tests/unit/test_camera_discovery/test_hybrid_monitor_capability_parsing.py . [  0%]
F.............                                                           [  4%]
tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py .F [  5%]
..FFF..F....F                                                            [  9%]
tests/unit/test_camera_discovery/test_hybrid_monitor_reconciliation.py . [  9%]
.......                                                                  [ 12%]
tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py F. [ 12%]
.FFFFFF.F                                                                [ 15%]
tests/unit/test_camera_discovery/test_simple_monitor.py ...              [ 16%]
tests/unit/test_camera_discovery/test_udev_processing.py F               [ 16%]
tests/unit/test_camera_service/test_config_manager.py .................. [ 22%]
                                                                         [ 22%]
tests/unit/test_camera_service/test_logging_config.py ....F..F.......... [ 27%]
....                                                                     [ 29%]
tests/unit/test_camera_service/test_service_manager_lifecycle.py ....    [ 30%]
tests/unit/test_configuration_validation.py ..FFF.F.                     [ 32%]
tests/unit/test_mediamtx_wrapper/test_controller_configuration.py ...F.F [ 34%]
F.F..F                                                                   [ 36%]
tests/unit/test_mediamtx_wrapper/test_controller_health_monitoring.py .F [ 37%]
F.F.....                                                                 [ 39%]
tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py F [ 40%]
FF.FFF.F                                                                 [ 42%]
tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py FF. [ 43%]
FFF.                                                                     [ 44%]
tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py F. [ 45%]
F.FFFF.FF.F.                                                             [ 49%]
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py F [ 49%]
FFF..FF                                                                  [ 51%]
tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py F [ 51%]
FFFFF                                                                    [ 53%]
tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py F [ 53%]
FFFFFF                                                                   [ 55%]
tests/unit/test_security/test_api_key_handler.py ....................... [ 62%]
...                                                                      [ 63%]
tests/unit/test_security/test_auth_manager.py .......................    [ 70%]
tests/unit/test_security/test_jwt_handler.py .........................   [ 78%]
tests/unit/test_security/test_middleware.py ............................ [ 87%]
..                                                                       [ 87%]
tests/unit/test_service_manager.py ....                                  [ 89%]
tests/unit/test_websocket_bind.py .                                      [ 89%]
tests/unit/test_websocket_server/test_server_method_handlers.py ....FFF. [ 91%]
FF..F                                                                    [ 93%]
tests/unit/test_websocket_server/test_server_notifications.py .....F.... [ 96%]
..                                                                       [ 97%]
tests/unit/test_websocket_server/test_server_status_aggregation.py FFFFF [ 98%]
FF.F                                                                     [100%]

=================================== FAILURES ===================================
_ TestCapabilityParsingVariations.test_capability_parsing_malformed_v4l2_outputs _

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_capability_parsing.TestCapabilityParsingVariations object at 0x7faac7fd8ca0>
monitor = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac820b5e0>

    @pytest.mark.asyncio
    async def test_capability_parsing_malformed_v4l2_outputs(self, monitor):
        """Test capability detection resilience against malformed v4l2-ctl outputs."""
    
        malformed_outputs = [
            # Truncated output
            '{"incomplete": "json"',
            # Non-JSON output when JSON expected
            "Error: device busy\nRetry later",
            # Empty output
            "",
            # Binary garbage
            b"\x00\x01\x02\x03invalid".decode("utf-8", errors="ignore"),
            # Partial v4l2-ctl output
            "Driver Info:\n  Driver name   : uvcvideo\n  Card type     :",  # Cut off
            # Mixed encoding issues
            "Camera: Café Français\nResolution: 1920×1080",  # Unicode chars
        ]
    
        device_path = "/dev/video0"
    
        for malformed_output in malformed_outputs:
            # Mock subprocess to return malformed output
            mock_process = Mock()
            mock_process.stdout = malformed_output
            mock_process.stderr = ""
            mock_process.returncode = 0
    
            with patch("subprocess.run", return_value=mock_process):
                result = await monitor._probe_device_capabilities(device_path)
    
            # Should handle malformation gracefully
            assert isinstance(result, CapabilityDetectionResult)
            assert result.detected == (
                len(result.formats) > 0 or len(result.resolutions) > 0
            )
>           assert result.error is None or "parsing" in result.error.lower()
E           AssertionError: assert ('Failed to probe basic device information (timeout or device unavailable)' is None or 'parsing' in 'failed to probe basic device information (timeout or device unavailable)')
E            +  where 'Failed to probe basic device information (timeout or device unavailable)' = CapabilityDetectionResult(device_path='/dev/video0', detected=False, accessible=False, device_name=None, driver=None, ...tics={'probe_start': 1754827771.3478525, 'timeout_threshold': 2.0, 'parsing_stages': [], 'device_info_success': False}).error
E            +  and   'failed to probe basic device information (timeout or device unavailable)' = <built-in method lower of str object at 0x7faac8265eb0>()
E            +    where <built-in method lower of str object at 0x7faac8265eb0> = 'Failed to probe basic device information (timeout or device unavailable)'.lower
E            +      where 'Failed to probe basic device information (timeout or device unavailable)' = CapabilityDetectionResult(device_path='/dev/video0', detected=False, accessible=False, device_name=None, driver=None, ...tics={'probe_start': 1754827771.3478525, 'timeout_threshold': 2.0, 'parsing_stages': [], 'device_info_success': False}).error

tests/unit/test_camera_discovery/test_hybrid_monitor_capability_parsing.py:116: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
_ TestCapabilityParsingVariations.test_capability_parsing_malformed_v4l2_outputs _

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_comprehensive.TestCapabilityParsingVariations object at 0x7faac820b160>
monitor = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac66795d0>

    @pytest.mark.asyncio
    async def test_capability_parsing_malformed_v4l2_outputs(self, monitor):
        """Test capability detection resilience against malformed v4l2-ctl outputs."""
    
        malformed_outputs = [
            # Empty/minimal outputs
            ("", False, "empty output"),
            ("v4l2-ctl: error", False, "error output"),
            # Partial outputs
            (
                "Card type: USB Camera\nDriver name: uvcvideo",
                True,
                "minimal valid info",
            ),
            ("Some random text without useful info", False, "random text"),
            # Malformed format sections
            ("Format [0]: corrupted data\nSize: invalid", False, "corrupted format"),
            (
                "Valid start\n[CORRUPTED MIDDLE SECTION]\nValid end",
                False,
                "corrupted middle",
            ),
            # Mixed valid/invalid data
            (
                "Card type: USB Camera\nFormat [0]: corrupted\nDriver: uvcvideo",
                False,
                "mixed valid/invalid",
            ),
        ]
    
        for output, expected_valid, description in malformed_outputs:
            # Mock subprocess to return our test output
            with patch("asyncio.create_subprocess_exec") as mock_subprocess:
                mock_process = AsyncMock()
                mock_process.communicate.return_value = (output.encode(), b"")
                mock_process.returncode = 0
                mock_subprocess.return_value = mock_process
    
                # Test capability detection
                result = await monitor._probe_device_capabilities("/dev/video0")
>               assert result.detected == expected_valid, f"Failed for {description}"
E               AssertionError: Failed for mixed valid/invalid
E               assert True == False
E                +  where True = CapabilityDetectionResult(device_path='/dev/video0', detected=True, accessible=True, device_name='USB Camera', driver=...s': True, 'formats_found': 0, 'resolutions_found': 0, 'frame_rates_found': 6, 'probe_duration': 0.0015516281127929688}).detected

tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py:116: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
_ TestUdevEventProcessingAndRaceConditions.test_udev_event_filtering_comprehensive _

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_comprehensive.TestUdevEventProcessingAndRaceConditions object at 0x7faac8208f40>
monitor = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac66cbe50>

    @pytest.mark.asyncio
    async def test_udev_event_filtering_comprehensive(self, monitor):
        """Test comprehensive udev event filtering logic."""
    
        # Mock udev device with various properties
        mock_device = Mock()
        mock_device.device_node = "/dev/video0"
        mock_device.action = "add"
        mock_device.get.return_value = "video4linux"
    
        # Test device addition
        await monitor._process_udev_device_event(mock_device)
    
        # Verify device was processed
>       assert "/dev/video0" in monitor._known_devices
E       AssertionError: assert '/dev/video0' in {}
E        +  where {} = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac66cbe50>._known_devices

tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py:195: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
------------------------------ Captured log call -------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video0 detected via udev 'add' but not accessible
_ TestUdevEventProcessingAndRaceConditions.test_udev_race_condition_simulation _

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_comprehensive.TestUdevEventProcessingAndRaceConditions object at 0x7faac820a950>
monitor = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac820b5e0>

    @pytest.mark.asyncio
    async def test_udev_race_condition_simulation(self, monitor):
        """Test race condition handling between udev events and polling."""
    
        device_path = "/dev/video0"
    
        # Simulate rapid add/remove/add sequence
        await self._simulate_delayed_udev_event(monitor, device_path, "add", 0.0)
        await self._simulate_delayed_udev_event(monitor, device_path, "remove", 0.1)
        await self._simulate_delayed_udev_event(monitor, device_path, "add", 0.2)
    
        # Verify final state is consistent
>       assert device_path in monitor._known_devices
E       AssertionError: assert '/dev/video0' in {}
E        +  where {} = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac820b5e0>._known_devices

tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py:216: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
------------------------------ Captured log call -------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video0 detected via udev 'add' but not accessible
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video0 detected via udev 'add' but not accessible
_ TestUdevEventProcessingAndRaceConditions.test_udev_change_event_status_detection _

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_comprehensive.TestUdevEventProcessingAndRaceConditions object at 0x7faac820beb0>
monitor = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac657ed10>

    @pytest.mark.asyncio
    async def test_udev_change_event_status_detection(self, monitor):
        """Test udev change event status detection and handling."""
    
        device_path = "/dev/video0"
        mock_device = Mock()
        mock_device.device_node = device_path
        mock_device.action = "change"
        mock_device.get.return_value = "video4linux"
    
        # Add device first
        add_device = Mock()
        add_device.device_node = device_path
        add_device.action = "add"
        add_device.get.return_value = "video4linux"
        await monitor._process_udev_device_event(add_device)
    
        # Then simulate change event
        await monitor._process_udev_device_event(mock_device)
    
        # Verify device still exists and status was updated
>       assert device_path in monitor._known_devices
E       AssertionError: assert '/dev/video0' in {}
E        +  where {} = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac657ed10>._known_devices

tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py:250: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
------------------------------ Captured log call -------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video0 detected via udev 'add' but not accessible
_____ TestPollingFallbackBehavior.test_polling_failure_backoff_with_jitter _____

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_comprehensive.TestPollingFallbackBehavior object at 0x7faac8209240>
monitor_no_udev = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac65c0340>

    @pytest.mark.asyncio
    async def test_polling_failure_backoff_with_jitter(self, monitor_no_udev):
        """Test polling failure backoff with jitter."""
    
    
        # Simulate polling failure
        with patch.object(monitor_no_udev, "_discover_cameras", side_effect=Exception("Test failure")):
            # Run one iteration of polling loop
            try:
                await monitor_no_udev._adaptive_polling_loop()
            except Exception:
                pass  # Expected due to mocked failure
    
        # Verify backoff was applied
>       assert monitor_no_udev._polling_failure_count > 0
E       assert 0 > 0
E        +  where 0 = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac65c0340>._polling_failure_count

tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py:320: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
_________ TestIntegrationAndLifecycle.test_end_to_end_device_workflow __________

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_comprehensive.TestIntegrationAndLifecycle object at 0x7faac820aa40>
monitor = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac6699c30>

    @pytest.mark.asyncio
    async def test_end_to_end_device_workflow(self, monitor):
        """Test end-to-end device detection and capability integration workflow."""
    
        monitor._set_test_mode(True)
        device_path = "/dev/video0"
    
        # Mock capability detection
        mock_capability = CapabilityDetectionResult(
            device_path=device_path,
            detected=True,
            accessible=True,
            resolutions=["1920x1080", "1280x720"],
            frame_rates=["30", "25", "15"],
            formats=[{"code": "YUYV", "description": "YUYV 4:2:2"}],
        )
    
        with patch.object(
            monitor, "_probe_device_capabilities", return_value=mock_capability
        ):
            # Create event handler to capture events
            captured_events = []
    
            def capture_event(event_data):
                captured_events.append(event_data)
    
            monitor.add_event_callback(capture_event)
    
            # Simulate device connection
            await monitor._inject_test_udev_event(device_path, "add")
    
            # Verify event was captured
>           assert len(captured_events) > 0
E           assert 0 > 0
E            +  where 0 = len([])

tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py:485: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
------------------------------ Captured log call -------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video0 detected via udev 'add' but not accessible
____________ TestUdevEventProcessing.test_udev_add_event_processing ____________

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_udev_fallback.TestUdevEventProcessing object at 0x7faac74aafe0>
monitor_with_udev = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac657c700>
mock_udev_device = <Mock id='140371448813584'>

    @pytest.mark.asyncio
    async def test_udev_add_event_processing(self, monitor_with_udev, mock_udev_device):
        """Test udev 'add' event processing and device registration."""
    
        # Mock device availability checks
        with (
            patch("pathlib.Path.exists", return_value=True),
            patch("builtins.open", return_value=Mock()),
            patch.object(
                monitor_with_udev, "_should_monitor_device", return_value=True
            ),
            patch.object(
                monitor_with_udev, "_create_camera_device_info",
                return_value=CameraDevice(
                    device="/dev/video0",
                    name="Test Camera",
                    status="CONNECTED"
                )
            ),
        ):
    
            # Setup event handler to capture events
            captured_events = []
    
            async def capture_event(event_data: CameraEventData):
                captured_events.append(event_data)
    
            monitor_with_udev.add_event_callback(capture_event)
    
            # Simulate udev add event
            mock_udev_device.action = "add"
            await monitor_with_udev._handle_udev_event(mock_udev_device)
    
            # Verify event processing
            assert len(captured_events) == 1
            event = captured_events[0]
            assert event.event_type == CameraEvent.CONNECTED
            assert event.device_path == "/dev/video0"
    
            # Verify device tracking
            assert "/dev/video0" in monitor_with_udev._known_devices
    
            # Verify stats update
            stats = monitor_with_udev.get_monitor_stats()
>           assert stats["udev_events_processed"] == 1
E           KeyError: 'udev_events_processed'

tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py:98: KeyError
___________ TestUdevEventProcessing.test_udev_event_race_conditions ____________

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_udev_fallback.TestUdevEventProcessing object at 0x7faac74aa980>
monitor_with_udev = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac66856f0>

    @pytest.mark.asyncio
    async def test_udev_event_race_conditions(self, monitor_with_udev):
        """Test rapid sequential udev events to detect race conditions."""
    
        captured_events = []
    
        async def capture_event(event_data: CameraEventData):
            captured_events.append(event_data)
    
        monitor_with_udev.add_event_callback(capture_event)
    
        # Create multiple mock devices
        devices = []
        for i in range(3):
            mock_device = Mock()
            mock_device.device_path = f"/dev/video{i}"
            mock_device.device_node = f"/dev/video{i}"
            mock_device.get.return_value = f"camera_{i}"
            mock_device.action = "add"
            mock_device.subsystem = "video4linux"
            devices.append(mock_device)
    
        with (
            patch("pathlib.Path.exists", return_value=True),
            patch("builtins.open", return_value=Mock()),
            patch.object(
                monitor_with_udev, "_should_monitor_device", return_value=True
            ),
        ):
    
            # Fire rapid sequential events
            tasks = []
            for device in devices:
                task = asyncio.create_task(monitor_with_udev._handle_udev_event(device))
                tasks.append(task)
    
            # Wait for all events to process
            await asyncio.gather(*tasks)
    
        # Verify all events processed correctly
>       assert len(captured_events) == 3
E       assert 0 == 3
E        +  where 0 = len([])

tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py:209: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video0 detected via udev 'add' but not accessible
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video1 detected via udev 'add' but not accessible
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video2 detected via udev 'add' but not accessible
__________ TestUdevEventProcessing.test_invalid_device_node_handling ___________

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_udev_fallback.TestUdevEventProcessing object at 0x7faac74aa560>
monitor_with_udev = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac654e710>

    @pytest.mark.asyncio
    async def test_invalid_device_node_handling(self, monitor_with_udev):
        """Test handling of udev events with invalid or inaccessible device nodes."""
    
        captured_events = []
    
        async def capture_event(event_data: CameraEventData):
            captured_events.append(event_data)
    
        monitor_with_udev.add_event_callback(capture_event)
    
        # Create mock device with invalid path
        mock_device = Mock()
        mock_device.device_path = "/dev/video999"  # Out of range
        mock_device.device_node = "/dev/video999"
        mock_device.get.return_value = "invalid_camera"
        mock_device.action = "add"
        mock_device.subsystem = "video4linux"
    
        # Simulate device path doesn't exist
        with patch("pathlib.Path.exists", return_value=False):
            await monitor_with_udev._handle_udev_event(mock_device)
    
        # Should not generate events for invalid devices
        assert len(captured_events) == 0
        assert len(monitor_with_udev._known_devices) == 0
    
        # Verify stats show filtered event
        stats = monitor_with_udev.get_monitor_stats()
>       assert stats["udev_events_filtered"] > 0
E       KeyError: 'udev_events_filtered'

tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py:247: KeyError
_____________ TestUdevEventProcessing.test_device_range_filtering ______________

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_udev_fallback.TestUdevEventProcessing object at 0x7faac74a9510>
monitor_with_udev = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac669b5b0>

    @pytest.mark.asyncio
    async def test_device_range_filtering(self, monitor_with_udev):
        """Test udev event filtering based on configured device range."""
    
        captured_events = []
    
        async def capture_event(event_data: CameraEventData):
            captured_events.append(event_data)
    
        monitor_with_udev.add_event_callback(capture_event)
    
        # Test devices both in and out of range
        test_cases = [
            ("/dev/video0", True),  # In range
            ("/dev/video1", True),  # In range
            ("/dev/video2", True),  # In range
            ("/dev/video5", False),  # Out of range
            ("/dev/video10", False),  # Out of range
        ]
    
        for device_path, should_process in test_cases:
            mock_device = Mock()
            mock_device.device_path = device_path
            mock_device.device_node = device_path
            mock_device.get.return_value = "test_camera"
            mock_device.action = "add"
            mock_device.subsystem = "video4linux"
    
            with (
                patch("pathlib.Path.exists", return_value=True),
                patch("builtins.open", return_value=Mock()),
            ):
    
                await monitor_with_udev._handle_udev_event(mock_device)
    
        # Only devices in range [0,1,2] should generate events
        processed_devices = [event.device_path for event in captured_events]
>       assert "/dev/video0" in processed_devices
E       AssertionError: assert '/dev/video0' in []

tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py:286: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video0 detected via udev 'add' but not accessible
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video1 detected via udev 'add' but not accessible
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video2 detected via udev 'add' but not accessible
__________ TestPollingFallback.test_polling_fallback_when_udev_stale ___________

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_udev_fallback.TestPollingFallback object at 0x7faac74aab90>
monitor_polling_fallback = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac842b1f0>

    @pytest.mark.asyncio
    async def test_polling_fallback_when_udev_stale(self, monitor_polling_fallback):
        """Test polling fallback activation when udev events become stale."""
    
        # Mock initial state - udev events are fresh
        monitor_polling_fallback._last_udev_event_time = time.time()
        monitor_polling_fallback._udev_event_freshness_threshold = (
            1.0  # 1 second threshold
        )
    
        captured_events = []
    
        async def capture_event(event_data: CameraEventData):
            captured_events.append(event_data)
    
        monitor_polling_fallback.add_event_callback(capture_event)
    
        # Mock device discovery to find new device
        with patch.object(
            monitor_polling_fallback, "_discover_cameras"
        ) as mock_discover:
            mock_discover.return_value = None  # Discovery method doesn't return
    
            # Fast-forward time to make udev events stale
            with patch("time.time", return_value=time.time() + 2.0):
                # Run polling cycle
                await monitor_polling_fallback._polling_monitor()
    
            # Verify polling was triggered due to stale udev events
>           mock_discover.assert_called_once()

tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <AsyncMock name='_discover_cameras' id='140371451677664'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected '_discover_cameras' to have been called once. Called 0 times.

/usr/lib/python3.10/unittest/mock.py:908: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
________ TestPollingFallback.test_adaptive_polling_interval_adjustment _________

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_udev_fallback.TestPollingFallback object at 0x7faac74a9e40>
monitor_polling_fallback = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac6596e30>

    @pytest.mark.asyncio
    async def test_adaptive_polling_interval_adjustment(self, monitor_polling_fallback):
        """Test adaptive polling interval adjustment based on udev event freshness."""
    
        initial_interval = monitor_polling_fallback._current_poll_interval
    
        # Simulate stale udev events (should increase polling frequency)
        monitor_polling_fallback._last_udev_event_time = (
            time.time() - 30.0
        )  # Very stale
        monitor_polling_fallback._udev_event_freshness_threshold = 15.0
    
        # Mock polling cycle execution
        with patch.object(monitor_polling_fallback, "_discover_cameras"):
            await monitor_polling_fallback._polling_monitor()
    
        # Polling interval should have decreased (higher frequency)
>       assert monitor_polling_fallback._current_poll_interval < initial_interval
E       assert 0.05 < 0.05
E        +  where 0.05 = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac6596e30>._current_poll_interval

tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py:355: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
______________ TestPollingFallback.test_polling_failure_recovery _______________

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_udev_fallback.TestPollingFallback object at 0x7faac74a9c60>
monitor_polling_fallback = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac667a260>

    @pytest.mark.asyncio
    async def test_polling_failure_recovery(self, monitor_polling_fallback):
        """Test polling failure handling and recovery behavior."""
    
        # Mock discovery failures
        failure_count = 0
    
        async def mock_discover_with_failures():
            nonlocal failure_count
            failure_count += 1
            if failure_count <= 3:  # Fail first 3 attempts
                raise OSError("Mock discovery failure")
            # Succeed on 4th attempt
            return None
    
        with patch.object(
            monitor_polling_fallback,
            "_discover_cameras",
            side_effect=mock_discover_with_failures,
        ):
    
            # Run multiple polling cycles
            for _ in range(5):
                try:
                    await monitor_polling_fallback._polling_monitor()
                except Exception:
                    pass  # Expected for first few attempts
    
        # Verify failure tracking
        assert (
            monitor_polling_fallback._polling_failure_count
            <= monitor_polling_fallback._max_consecutive_failures
        )
    
        # Stats should reflect failures and recovery
        stats = monitor_polling_fallback.get_monitor_stats()
>       assert stats["polling_cycles"] >= 5
E       assert 0 >= 5

tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py:401: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
_____________ TestPollingFallback.test_polling_only_mode_fallback ______________

self = <tests.unit.test_camera_discovery.test_hybrid_monitor_udev_fallback.TestPollingFallback object at 0x7faac74a9870>
monitor_polling_fallback = <src.camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac667ab30>

    @pytest.mark.asyncio
    async def test_polling_only_mode_fallback(self, monitor_polling_fallback):
        """Test operation when udev is completely unavailable (polling-only mode)."""
    
        # Disable udev completely
        with patch("src.camera_discovery.hybrid_monitor.HAS_PYUDEV", False):
            monitor_no_udev = HybridCameraMonitor(
                device_range=[0, 1],
                poll_interval=0.05,
                enable_capability_detection=False,
            )
    
            captured_events = []
    
            async def capture_event(event_data: CameraEventData):
                captured_events.append(event_data)
    
            monitor_no_udev.add_event_callback(capture_event)
    
            # Mock device existence for polling detection
            with (
                patch("pathlib.Path.exists", return_value=True),
                patch("builtins.open", return_value=Mock()),
            ):
    
                await monitor_no_udev._discover_cameras()
    
            # Should still detect devices through polling
            assert len(captured_events) > 0
    
            # Verify polling-only stats
            stats = monitor_no_udev.get_monitor_stats()
>           assert stats["polling_cycles"] > 0
E           assert 0 > 0

tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py:470: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
------------------------------ Captured log call -------------------------------
WARNING  src.camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
__________________________ test_udev_event_filtering ___________________________

monitor = <camera_discovery.hybrid_monitor.HybridCameraMonitor object at 0x7faac653d960>

    @pytest.mark.asyncio
    async def test_udev_event_filtering(monitor):
        class MockUdevDevice:
            def __init__(self, device_node, action):
                self.device_node = device_node
                self.action = action
    
        processed = []
    
        async def fake_handle(event_data):
            processed.append(event_data.device_path)
    
        monitor._handle_camera_event = fake_handle
        monitor._create_camera_device_info = AsyncMock()
    
        cases = [
            ("/dev/video0", "add", True),
            ("/dev/video5", "add", False),
        ]
    
        for node, action, should in cases:
            dev = MockUdevDevice(node, action)
            await monitor._process_udev_device_event(dev)
    
>       assert "/dev/video0" in processed
E       AssertionError: assert '/dev/video0' in []

tests/unit/test_camera_discovery/test_udev_processing.py:29: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  camera_discovery.hybrid_monitor:hybrid_monitor.py:247 pyudev not available - falling back to polling-only monitoring
------------------------------ Captured log call -------------------------------
WARNING  camera_discovery.hybrid_monitor:hybrid_monitor.py:516 Device /dev/video0 detected via udev 'add' but not accessible
_____________ TestJsonFormatter.test_json_formatter_with_exception _____________

self = <tests.unit.test_camera_service.test_logging_config.TestJsonFormatter object at 0x7faac738f040>

    def test_json_formatter_with_exception(self):
        """Test JSON formatter with exception information."""
        # TODO: HIGH: Test JSON formatter exception handling [Story:S14]
        formatter = JsonFormatter()
    
        try:
            raise ValueError("Test exception")
        except ValueError:
            exc_info = True
    
        record = logging.LogRecord(
            name="test",
            level=logging.ERROR,
            pathname="",
            lineno=0,
            msg="Error occurred",
            args=(),
            exc_info=exc_info,
        )
    
>       result = formatter.format(record)

tests/unit/test_camera_service/test_logging_config.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/camera_service/logging_config.py:76: in format
    log_entry["exception"] = self.formatException(record.exc_info)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <camera_service.logging_config.JsonFormatter object at 0x7faac669a770>
ei = True

    def formatException(self, ei):
        """
        Format and return the specified exception information as a string.
    
        This default implementation just uses
        traceback.print_exception()
        """
        sio = io.StringIO()
>       tb = ei[2]
E       TypeError: 'bool' object is not subscriptable

/usr/lib/python3.10/logging/__init__.py:632: TypeError
_______ TestConsoleFormatter.test_console_formatter_with_correlation_id ________

self = <tests.unit.test_camera_service.test_logging_config.TestConsoleFormatter object at 0x7faac738ead0>

    def test_console_formatter_with_correlation_id(self):
        """Test console formatter includes correlation ID."""
        # TODO: HIGH: Test console formatter correlation ID display [Story:S14]
        formatter = ConsoleFormatter("%(levelname)s - %(name)s - %(message)s")
        record = logging.LogRecord(
            name="test.module",
            level=logging.INFO,
            pathname="",
            lineno=0,
            msg="Test message",
            args=(),
            exc_info=None,
        )
        record.correlation_id = "test-456"
    
        result = formatter.format(record)
    
>       assert "[test-456]" in result
E       AssertionError: assert '[test-456]' in 'INFO - test.module - Test message'

tests/unit/test_camera_service/test_logging_config.py:232: AssertionError
_ TestConfigurationSchemaValidation.test_service_manager_config_instantiation __

self = <tests.unit.test_configuration_validation.TestConfigurationSchemaValidation object at 0x7faac74abdf0>

    def test_service_manager_config_instantiation(self):
        """Test that ServiceManager can create MediaMTXController with config object."""
    
        # Create a minimal valid config
        config_data = {
            'server': {
                'host': '0.0.0.0',
                'port': 8002,
                'max_connections': 100,
                'websocket_path': '/websocket'
            },
            'mediamtx': {
                'host': 'localhost',
                'api_port': 9997,
                'rtsp_port': 8554,
                'webrtc_port': 8889,
                'hls_port': 8888,
                'config_path': '/opt/mediamtx/config/mediamtx.yml',
                'recordings_path': '/opt/camera-service/recordings',
                'snapshots_path': '/opt/camera-service/snapshots',
                'health_check_interval': 30,
                'health_failure_threshold': 10,
                'health_circuit_breaker_timeout': 60,
                'health_max_backoff_interval': 120,
                'health_recovery_confirmation_threshold': 3,
                'backoff_base_multiplier': 2.0,
                'backoff_jitter_range': (0.8, 1.2),
                'process_termination_timeout': 3.0,
                'process_kill_timeout': 2.0,
            },
            'camera': {
                'poll_interval': 0.1,
                'enable_capability_detection': True,
                'capability_timeout': 5.0,
                'capability_retry_interval': 1.0,
                'capability_max_retries': 3
            },
            'logging': {
                'level': 'INFO',
                'file_enabled': True,
                'file_path': '/var/log/camera-service.log',
                'max_file_size': 10485760,
                'backup_count': 5,
                'console_enabled': True
            },
            'recording': {
                'enabled': True,
                'format': 'fmp4',
                'segment_duration': 3600,
                'max_segment_size': 524288000,
                'auto_cleanup': True,
                'cleanup_interval': 86400,
                'max_age': 604800,
                'max_size': 10737418240
            },
            'snapshots': {
                'enabled': True,
                'format': 'jpeg',
                'quality': 85,
                'max_width': 1920,
                'max_height': 1080,
                'auto_cleanup': True,
                'cleanup_interval': 3600,
                'max_age': 86400,
                'max_count': 1000
            }
        }
    
        # Create config object
        config = Config(**config_data)
    
        # Test that ServiceManager can be instantiated with this config
        # (We'll mock the actual service manager to avoid starting real services)
>       with pytest.raises(Exception) as exc_info:
E       Failed: DID NOT RAISE <class 'Exception'>

tests/unit/test_configuration_validation.py:171: Failed
_________ TestConfigurationSchemaValidation.test_config_default_values _________

self = <tests.unit.test_configuration_validation.TestConfigurationSchemaValidation object at 0x7faac74a8fd0>

    def test_config_default_values(self):
        """Test that default configuration values are valid."""
    
        # Create config with minimal data (should use defaults)
        config_data = {
            'server': {'host': '0.0.0.0'},
            'mediamtx': {'host': 'localhost'},
            'camera': {},
            'logging': {},
            'recording': {},
            'snapshots': {}
        }
    
        config = Config(**config_data)
    
        # Verify that all required fields have valid default values
>       assert config.mediamtx.host == 'localhost'
E       AttributeError: 'dict' object has no attribute 'host'

tests/unit/test_configuration_validation.py:198: AttributeError
__ TestConfigurationSchemaValidation.test_config_serialization_compatibility ___

self = <tests.unit.test_configuration_validation.TestConfigurationSchemaValidation object at 0x7faac74a9660>

    def test_config_serialization_compatibility(self):
        """Test that configuration can be serialized and deserialized without data loss."""
    
        # Create a complete config
        config_data = {
            'server': {
                'host': '0.0.0.0',
                'port': 8002,
                'max_connections': 100,
                'websocket_path': '/websocket'
            },
            'mediamtx': {
                'host': 'localhost',
                'api_port': 9997,
                'rtsp_port': 8554,
                'webrtc_port': 8889,
                'hls_port': 8888,
                'config_path': '/opt/mediamtx/config/mediamtx.yml',
                'recordings_path': '/opt/camera-service/recordings',
                'snapshots_path': '/opt/camera-service/snapshots',
                'health_check_interval': 30,
                'health_failure_threshold': 10,
                'health_circuit_breaker_timeout': 60,
                'health_max_backoff_interval': 120,
                'health_recovery_confirmation_threshold': 3,
                'backoff_base_multiplier': 2.0,
                'backoff_jitter_range': (0.8, 1.2),
                'process_termination_timeout': 3.0,
                'process_kill_timeout': 2.0,
            },
            'camera': {
                'poll_interval': 0.1,
                'enable_capability_detection': True
            },
            'logging': {
                'level': 'INFO',
                'file_enabled': True
            },
            'recording': {
                'enabled': True,
                'format': 'fmp4'
            },
            'snapshots': {
                'enabled': True,
                'format': 'jpeg'
            }
        }
    
        config = Config(**config_data)
    
        # Serialize to dict
>       config_dict = config.to_dict()

tests/unit/test_configuration_validation.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/camera_service/config.py:158: in to_dict
    "server": asdict(self.server),
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = {'host': '0.0.0.0', 'max_connections': 100, 'port': 8002, 'websocket_path': '/websocket'}

    def asdict(obj, *, dict_factory=dict):
        """Return the fields of a dataclass instance as a new dictionary mapping
        field names to field values.
    
        Example usage:
    
          @dataclass
          class C:
              x: int
              y: int
    
          c = C(1, 2)
          assert asdict(c) == {'x': 1, 'y': 2}
    
        If given, 'dict_factory' will be used instead of built-in dict.
        The function applies recursively to field values that are
        dataclass instances. This will also look into built-in containers:
        tuples, lists, and dicts.
        """
        if not _is_dataclass_instance(obj):
>           raise TypeError("asdict() should be called on dataclass instances")
E           TypeError: asdict() should be called on dataclass instances

/usr/lib/python3.10/dataclasses.py:1237: TypeError
____ TestConfigurationFileValidation.test_default_yaml_config_compatibility ____

self = <tests.unit.test_configuration_validation.TestConfigurationFileValidation object at 0x7faac74ab6a0>

    def test_default_yaml_config_compatibility(self):
        """Test that the default YAML configuration file is compatible with the schema."""
    
        # This test ensures that config/default.yaml contains all required fields
        # and that they match the expected types
    
        # Import the default config
        from src.camera_service.config import ConfigManager
    
        config_manager = ConfigManager()
    
        # Try to load the default configuration
        try:
            config = config_manager.load_config()
    
            # Verify that all required MediaMTX parameters are present
            assert hasattr(config.mediamtx, 'health_check_interval')
            assert hasattr(config.mediamtx, 'health_failure_threshold')
            assert hasattr(config.mediamtx, 'health_circuit_breaker_timeout')
            assert hasattr(config.mediamtx, 'health_max_backoff_interval')
            assert hasattr(config.mediamtx, 'health_recovery_confirmation_threshold')
            assert hasattr(config.mediamtx, 'backoff_base_multiplier')
            assert hasattr(config.mediamtx, 'backoff_jitter_range')
            assert hasattr(config.mediamtx, 'process_termination_timeout')
            assert hasattr(config.mediamtx, 'process_kill_timeout')
    
            # Verify types
            assert isinstance(config.mediamtx.health_check_interval, int)
            assert isinstance(config.mediamtx.health_failure_threshold, int)
            assert isinstance(config.mediamtx.backoff_base_multiplier, float)
>           assert isinstance(config.mediamtx.backoff_jitter_range, tuple)
E           AssertionError: assert False
E            +  where False = isinstance([0.8, 1.2], tuple)
E            +    where [0.8, 1.2] = MediaMTXConfig(host='127.0.0.1', api_port=9997, rtsp_port=8554, webrtc_port=8889, hls_port=8888, config_path='/opt/cam...ackoff_base_multiplier=2.0, backoff_jitter_range=[0.8, 1.2], process_termination_timeout=3.0, process_kill_timeout=2.0).backoff_jitter_range
E            +      where MediaMTXConfig(host='127.0.0.1', api_port=9997, rtsp_port=8554, webrtc_port=8889, hls_port=8888, config_path='/opt/cam...ackoff_base_multiplier=2.0, backoff_jitter_range=[0.8, 1.2], process_termination_timeout=3.0, process_kill_timeout=2.0) = Config(server=ServerConfig(host='0.0.0.0', port=8002, websocket_path='/ws', max_connections=100), mediamtx=MediaMTXCon...', max_duration=3600, cleanup_after_days=30), snapshots=SnapshotConfig(format='jpg', quality=90, cleanup_after_days=7)).mediamtx

tests/unit/test_configuration_validation.py:330: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.unit.test_configuration_validation.TestConfigurationFileValidation object at 0x7faac74ab6a0>

    def test_default_yaml_config_compatibility(self):
        """Test that the default YAML configuration file is compatible with the schema."""
    
        # This test ensures that config/default.yaml contains all required fields
        # and that they match the expected types
    
        # Import the default config
        from src.camera_service.config import ConfigManager
    
        config_manager = ConfigManager()
    
        # Try to load the default configuration
        try:
            config = config_manager.load_config()
    
            # Verify that all required MediaMTX parameters are present
            assert hasattr(config.mediamtx, 'health_check_interval')
            assert hasattr(config.mediamtx, 'health_failure_threshold')
            assert hasattr(config.mediamtx, 'health_circuit_breaker_timeout')
            assert hasattr(config.mediamtx, 'health_max_backoff_interval')
            assert hasattr(config.mediamtx, 'health_recovery_confirmation_threshold')
            assert hasattr(config.mediamtx, 'backoff_base_multiplier')
            assert hasattr(config.mediamtx, 'backoff_jitter_range')
            assert hasattr(config.mediamtx, 'process_termination_timeout')
            assert hasattr(config.mediamtx, 'process_kill_timeout')
    
            # Verify types
            assert isinstance(config.mediamtx.health_check_interval, int)
            assert isinstance(config.mediamtx.health_failure_threshold, int)
            assert isinstance(config.mediamtx.backoff_base_multiplier, float)
            assert isinstance(config.mediamtx.backoff_jitter_range, tuple)
    
        except Exception as e:
>           pytest.fail(f"Default configuration failed to load: {e}")
E           Failed: Default configuration failed to load: assert False
E            +  where False = isinstance([0.8, 1.2], tuple)
E            +    where [0.8, 1.2] = MediaMTXConfig(host='127.0.0.1', api_port=9997, rtsp_port=8554, webrtc_port=8889, hls_port=8888, config_path='/opt/cam...ackoff_base_multiplier=2.0, backoff_jitter_range=[0.8, 1.2], process_termination_timeout=3.0, process_kill_timeout=2.0).backoff_jitter_range
E            +      where MediaMTXConfig(host='127.0.0.1', api_port=9997, rtsp_port=8554, webrtc_port=8889, hls_port=8888, config_path='/opt/cam...ackoff_base_multiplier=2.0, backoff_jitter_range=[0.8, 1.2], process_termination_timeout=3.0, process_kill_timeout=2.0) = Config(server=ServerConfig(host='0.0.0.0', port=8002, websocket_path='/ws', max_connections=100), mediamtx=MediaMTXCon...', max_duration=3600, cleanup_after_days=30), snapshots=SnapshotConfig(format='jpg', quality=90, cleanup_after_days=7)).mediamtx

tests/unit/test_configuration_validation.py:333: Failed
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:44 - src.camera_service.config - INFO - [51f93e2f] Configuration loaded successfully from config/default.yaml
------------------------------ Captured log call -------------------------------
INFO     src.camera_service.config:config.py:241 Configuration loaded successfully from config/default.yaml
__ TestConfigurationValidation.test_configuration_validation_pattern_matching __

self = <tests.unit.test_mediamtx_wrapper.test_controller_configuration.TestConfigurationValidation object at 0x7faac738caf0>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4962ef0>

    @pytest.mark.asyncio
    async def test_configuration_validation_pattern_matching(self, controller):
        """Test validation enforces string patterns (e.g., IP addresses)."""
        invalid_patterns = [
            {"apiAddress": "invalid_ip"},
            {"metricsAddress": "not.an.ip.address"},
            {"rtspAddress": "999.999.999.999"},  # Invalid IP
            {"webrtcAddress": "localhost:abc"},  # Invalid port format
        ]
    
        for invalid_config in invalid_patterns:
>           with pytest.raises(ValueError, match="Invalid format"):
E           Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_mediamtx_wrapper/test_controller_configuration.py:145: Failed
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - ERROR - [51f93e2f] Configuration validation failed: Invalid format for apiAddress: invalid_ip
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - ERROR - [51f93e2f] Configuration validation failed: Invalid format for metricsAddress: not.an.ip.address
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - INFO - [51f93e2f] Updating MediaMTX configuration: ['rtspAddress']
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - INFO - [51f93e2f] MediaMTX configuration updated successfully: ['rtspAddress']
------------------------------ Captured log call -------------------------------
ERROR    src.mediamtx_wrapper.controller:controller.py:1307 Configuration validation failed: Invalid format for apiAddress: invalid_ip
ERROR    src.mediamtx_wrapper.controller:controller.py:1307 Configuration validation failed: Invalid format for metricsAddress: not.an.ip.address
INFO     src.mediamtx_wrapper.controller:controller.py:1311 Updating MediaMTX configuration: ['rtspAddress']
INFO     src.mediamtx_wrapper.controller:controller.py:1320 MediaMTX configuration updated successfully: ['rtspAddress']
_ TestConfigurationValidation.test_configuration_update_api_failure_safe_fallback _

self = <tests.unit.test_mediamtx_wrapper.test_controller_configuration.TestConfigurationValidation object at 0x7faac738d600>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac66cbfd0>

    @pytest.mark.asyncio
    async def test_configuration_update_api_failure_safe_fallback(self, controller):
        """Test safe fallback behavior when MediaMTX API fails during update."""
        # Valid configuration
        valid_config = {"logLevel": "debug", "api": True}
    
        # Mock API failure
        error_response = self._mock_response(500, text_data="Internal Server Error")
        controller._session.post = AsyncMock(return_value=error_response)
    
        # Should raise ValueError (not crash system)
        with pytest.raises(ValueError, match="Failed to update configuration"):
>           await controller.update_configuration(valid_config)

tests/unit/test_mediamtx_wrapper/test_controller_configuration.py:194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac66cbfd0>
config_updates = {'api': True, 'logLevel': 'debug'}

    async def update_configuration(self, config_updates: Dict[str, Any]) -> bool:
        """
        Update MediaMTX configuration dynamically with enhanced validation and error handling.
    
        Args:
            config_updates: Configuration parameters to update
    
        Returns:
            True if configuration was updated successfully
    
        Raises:
            ValueError: If configuration is invalid
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not config_updates:
            raise ValueError("Configuration updates are required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Enhanced configuration validation schema
        valid_config_schema = {
            "logLevel": {"type": str, "values": ["error", "warn", "info", "debug"]},
            "logDestinations": {"type": list},
            "readTimeout": {"type": (str, int), "min": 1, "max": 300},
            "writeTimeout": {"type": (str, int), "min": 1, "max": 300},
            "readBufferCount": {"type": int, "min": 1, "max": 4096},
            "udpMaxPayloadSize": {"type": int, "min": 1024, "max": 65507},
            "runOnConnect": {"type": str},
            "runOnConnectRestart": {"type": bool},
            "api": {"type": bool},
            "apiAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "metrics": {"type": bool},
            "metricsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "pprof": {"type": bool},
            "pprofAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtsp": {"type": bool},
            "rtspAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtspsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtmp": {"type": bool},
            "rtmpAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtmps": {"type": bool},
            "rtmpsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "hls": {"type": bool},
            "hlsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "hlsAllowOrigin": {"type": str},
            "webrtc": {"type": bool},
            "webrtcAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
        }
    
        # Validate configuration keys
        unknown_keys = set(config_updates.keys()) - set(valid_config_schema.keys())
        if unknown_keys:
            error_msg = f"Unknown configuration keys: {list(unknown_keys)}"
            self._logger.error(error_msg, extra={"correlation_id": correlation_id})
            raise ValueError(error_msg)
    
        # Enhanced configuration value validation with error accumulation
        validation_errors = []
        for key, value in config_updates.items():
            schema = valid_config_schema[key]
    
            # Ensure schema is a dictionary
            if not isinstance(schema, dict):
                validation_errors.append(f"Invalid schema for {key}: expected dict, got {type(schema)}")
                continue
    
            # Type validation
            if "type" in schema and not isinstance(value, schema["type"]):
                validation_errors.append(
                    f"Invalid type for {key}: expected {schema['type']}, got {type(value)}"
                )
                continue
    
            # Value constraints validation
            if "values" in schema and value not in schema["values"]:
                validation_errors.append(
                    f"Invalid value for {key}: {value}, allowed values: {schema['values']}"
                )
    
            if (
                "min" in schema
                and isinstance(value, (int, float))
                and value < schema["min"]
            ):
                validation_errors.append(
                    f"Value for {key} too small: {value}, minimum: {schema['min']}"
                )
    
            if (
                "max" in schema
                and isinstance(value, (int, float))
                and value > schema["max"]
            ):
                validation_errors.append(
                    f"Value for {key} too large: {value}, maximum: {schema['max']}"
                )
    
            # Pattern validation for string types
            if "pattern" in schema and isinstance(value, str):
                import re
    
                if not re.match(schema["pattern"], value):
                    validation_errors.append(f"Invalid format for {key}: {value}")
    
        if validation_errors:
            error_msg = (
                f"Configuration validation failed: {'; '.join(validation_errors)}"
            )
            self._logger.error(error_msg, extra={"correlation_id": correlation_id})
            raise ValueError(error_msg)
    
        try:
            self._logger.info(
                f"Updating MediaMTX configuration: {list(config_updates.keys())}",
                extra={"correlation_id": correlation_id},
            )
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/global/patch", json=config_updates
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:1316: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - INFO - [51f93e2f] Updating MediaMTX configuration: ['logLevel', 'api']
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1311 Updating MediaMTX configuration: ['logLevel', 'api']
_ TestConfigurationValidation.test_configuration_update_network_error_handling _

self = <tests.unit.test_mediamtx_wrapper.test_controller_configuration.TestConfigurationValidation object at 0x7faac738d1e0>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac495f430>

    @pytest.mark.asyncio
    async def test_configuration_update_network_error_handling(self, controller):
        """Test network error handling during configuration update."""
        valid_config = {"logLevel": "info"}
    
        # Mock network error
        controller._session.post = AsyncMock(
            side_effect=aiohttp.ClientError("Connection refused")
        )
    
        with pytest.raises(ConnectionError, match="MediaMTX unreachable"):
>           await controller.update_configuration(valid_config)

tests/unit/test_mediamtx_wrapper/test_controller_configuration.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac495f430>
config_updates = {'logLevel': 'info'}

    async def update_configuration(self, config_updates: Dict[str, Any]) -> bool:
        """
        Update MediaMTX configuration dynamically with enhanced validation and error handling.
    
        Args:
            config_updates: Configuration parameters to update
    
        Returns:
            True if configuration was updated successfully
    
        Raises:
            ValueError: If configuration is invalid
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not config_updates:
            raise ValueError("Configuration updates are required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Enhanced configuration validation schema
        valid_config_schema = {
            "logLevel": {"type": str, "values": ["error", "warn", "info", "debug"]},
            "logDestinations": {"type": list},
            "readTimeout": {"type": (str, int), "min": 1, "max": 300},
            "writeTimeout": {"type": (str, int), "min": 1, "max": 300},
            "readBufferCount": {"type": int, "min": 1, "max": 4096},
            "udpMaxPayloadSize": {"type": int, "min": 1024, "max": 65507},
            "runOnConnect": {"type": str},
            "runOnConnectRestart": {"type": bool},
            "api": {"type": bool},
            "apiAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "metrics": {"type": bool},
            "metricsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "pprof": {"type": bool},
            "pprofAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtsp": {"type": bool},
            "rtspAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtspsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtmp": {"type": bool},
            "rtmpAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtmps": {"type": bool},
            "rtmpsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "hls": {"type": bool},
            "hlsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "hlsAllowOrigin": {"type": str},
            "webrtc": {"type": bool},
            "webrtcAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
        }
    
        # Validate configuration keys
        unknown_keys = set(config_updates.keys()) - set(valid_config_schema.keys())
        if unknown_keys:
            error_msg = f"Unknown configuration keys: {list(unknown_keys)}"
            self._logger.error(error_msg, extra={"correlation_id": correlation_id})
            raise ValueError(error_msg)
    
        # Enhanced configuration value validation with error accumulation
        validation_errors = []
        for key, value in config_updates.items():
            schema = valid_config_schema[key]
    
            # Ensure schema is a dictionary
            if not isinstance(schema, dict):
                validation_errors.append(f"Invalid schema for {key}: expected dict, got {type(schema)}")
                continue
    
            # Type validation
            if "type" in schema and not isinstance(value, schema["type"]):
                validation_errors.append(
                    f"Invalid type for {key}: expected {schema['type']}, got {type(value)}"
                )
                continue
    
            # Value constraints validation
            if "values" in schema and value not in schema["values"]:
                validation_errors.append(
                    f"Invalid value for {key}: {value}, allowed values: {schema['values']}"
                )
    
            if (
                "min" in schema
                and isinstance(value, (int, float))
                and value < schema["min"]
            ):
                validation_errors.append(
                    f"Value for {key} too small: {value}, minimum: {schema['min']}"
                )
    
            if (
                "max" in schema
                and isinstance(value, (int, float))
                and value > schema["max"]
            ):
                validation_errors.append(
                    f"Value for {key} too large: {value}, maximum: {schema['max']}"
                )
    
            # Pattern validation for string types
            if "pattern" in schema and isinstance(value, str):
                import re
    
                if not re.match(schema["pattern"], value):
                    validation_errors.append(f"Invalid format for {key}: {value}")
    
        if validation_errors:
            error_msg = (
                f"Configuration validation failed: {'; '.join(validation_errors)}"
            )
            self._logger.error(error_msg, extra={"correlation_id": correlation_id})
            raise ValueError(error_msg)
    
        try:
            self._logger.info(
                f"Updating MediaMTX configuration: {list(config_updates.keys())}",
                extra={"correlation_id": correlation_id},
            )
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/global/patch", json=config_updates
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:1316: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - INFO - [51f93e2f] Updating MediaMTX configuration: ['logLevel']
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1311 Updating MediaMTX configuration: ['logLevel']
_ TestConfigurationValidation.test_configuration_validation_valid_config_success _

self = <tests.unit.test_mediamtx_wrapper.test_controller_configuration.TestConfigurationValidation object at 0x7faac74c34f0>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac842a8f0>

    @pytest.mark.asyncio
    async def test_configuration_validation_valid_config_success(self, controller):
        """Test successful configuration update with valid parameters."""
        valid_config = {
            "logLevel": "debug",
            "api": True,
            "readTimeout": 30,
            "readBufferCount": 512,
            "apiAddress": "127.0.0.1:9997",
        }
    
        # Mock successful API response
        success_response = self._mock_response(200)
        controller._session.post = AsyncMock(return_value=success_response)
    
>       result = await controller.update_configuration(valid_config)

tests/unit/test_mediamtx_wrapper/test_controller_configuration.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac842a8f0>
config_updates = {'api': True, 'apiAddress': '127.0.0.1:9997', 'logLevel': 'debug', 'readBufferCount': 512, ...}

    async def update_configuration(self, config_updates: Dict[str, Any]) -> bool:
        """
        Update MediaMTX configuration dynamically with enhanced validation and error handling.
    
        Args:
            config_updates: Configuration parameters to update
    
        Returns:
            True if configuration was updated successfully
    
        Raises:
            ValueError: If configuration is invalid
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not config_updates:
            raise ValueError("Configuration updates are required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Enhanced configuration validation schema
        valid_config_schema = {
            "logLevel": {"type": str, "values": ["error", "warn", "info", "debug"]},
            "logDestinations": {"type": list},
            "readTimeout": {"type": (str, int), "min": 1, "max": 300},
            "writeTimeout": {"type": (str, int), "min": 1, "max": 300},
            "readBufferCount": {"type": int, "min": 1, "max": 4096},
            "udpMaxPayloadSize": {"type": int, "min": 1024, "max": 65507},
            "runOnConnect": {"type": str},
            "runOnConnectRestart": {"type": bool},
            "api": {"type": bool},
            "apiAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "metrics": {"type": bool},
            "metricsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "pprof": {"type": bool},
            "pprofAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtsp": {"type": bool},
            "rtspAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtspsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtmp": {"type": bool},
            "rtmpAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtmps": {"type": bool},
            "rtmpsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "hls": {"type": bool},
            "hlsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "hlsAllowOrigin": {"type": str},
            "webrtc": {"type": bool},
            "webrtcAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
        }
    
        # Validate configuration keys
        unknown_keys = set(config_updates.keys()) - set(valid_config_schema.keys())
        if unknown_keys:
            error_msg = f"Unknown configuration keys: {list(unknown_keys)}"
            self._logger.error(error_msg, extra={"correlation_id": correlation_id})
            raise ValueError(error_msg)
    
        # Enhanced configuration value validation with error accumulation
        validation_errors = []
        for key, value in config_updates.items():
            schema = valid_config_schema[key]
    
            # Ensure schema is a dictionary
            if not isinstance(schema, dict):
                validation_errors.append(f"Invalid schema for {key}: expected dict, got {type(schema)}")
                continue
    
            # Type validation
            if "type" in schema and not isinstance(value, schema["type"]):
                validation_errors.append(
                    f"Invalid type for {key}: expected {schema['type']}, got {type(value)}"
                )
                continue
    
            # Value constraints validation
            if "values" in schema and value not in schema["values"]:
                validation_errors.append(
                    f"Invalid value for {key}: {value}, allowed values: {schema['values']}"
                )
    
            if (
                "min" in schema
                and isinstance(value, (int, float))
                and value < schema["min"]
            ):
                validation_errors.append(
                    f"Value for {key} too small: {value}, minimum: {schema['min']}"
                )
    
            if (
                "max" in schema
                and isinstance(value, (int, float))
                and value > schema["max"]
            ):
                validation_errors.append(
                    f"Value for {key} too large: {value}, maximum: {schema['max']}"
                )
    
            # Pattern validation for string types
            if "pattern" in schema and isinstance(value, str):
                import re
    
                if not re.match(schema["pattern"], value):
                    validation_errors.append(f"Invalid format for {key}: {value}")
    
        if validation_errors:
            error_msg = (
                f"Configuration validation failed: {'; '.join(validation_errors)}"
            )
            self._logger.error(error_msg, extra={"correlation_id": correlation_id})
            raise ValueError(error_msg)
    
        try:
            self._logger.info(
                f"Updating MediaMTX configuration: {list(config_updates.keys())}",
                extra={"correlation_id": correlation_id},
            )
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/global/patch", json=config_updates
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:1316: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - INFO - [51f93e2f] Updating MediaMTX configuration: ['logLevel', 'api', 'readTimeout', 'readBufferCount', 'apiAddress']
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1311 Updating MediaMTX configuration: ['logLevel', 'api', 'readTimeout', 'readBufferCount', 'apiAddress']
_ TestConfigurationValidation.test_configuration_validation_correlation_id_logging _

self = <tests.unit.test_mediamtx_wrapper.test_controller_configuration.TestConfigurationValidation object at 0x7faac74c2a10>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d27bb0>

    @pytest.mark.asyncio
    async def test_configuration_validation_correlation_id_logging(self, controller):
        """Test configuration validation includes correlation IDs in logging."""
        correlation_ids = []
    
        def mock_set_correlation_id(cid):
            correlation_ids.append(cid)
    
        with patch(
            "src.mediamtx_wrapper.controller.set_correlation_id",
            side_effect=mock_set_correlation_id,
        ):
            # Mock successful response
            success_response = self._mock_response(200)
            controller._session.post = AsyncMock(return_value=success_response)
    
>           await controller.update_configuration({"logLevel": "info"})

tests/unit/test_mediamtx_wrapper/test_controller_configuration.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d27bb0>
config_updates = {'logLevel': 'info'}

    async def update_configuration(self, config_updates: Dict[str, Any]) -> bool:
        """
        Update MediaMTX configuration dynamically with enhanced validation and error handling.
    
        Args:
            config_updates: Configuration parameters to update
    
        Returns:
            True if configuration was updated successfully
    
        Raises:
            ValueError: If configuration is invalid
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not config_updates:
            raise ValueError("Configuration updates are required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Enhanced configuration validation schema
        valid_config_schema = {
            "logLevel": {"type": str, "values": ["error", "warn", "info", "debug"]},
            "logDestinations": {"type": list},
            "readTimeout": {"type": (str, int), "min": 1, "max": 300},
            "writeTimeout": {"type": (str, int), "min": 1, "max": 300},
            "readBufferCount": {"type": int, "min": 1, "max": 4096},
            "udpMaxPayloadSize": {"type": int, "min": 1024, "max": 65507},
            "runOnConnect": {"type": str},
            "runOnConnectRestart": {"type": bool},
            "api": {"type": bool},
            "apiAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "metrics": {"type": bool},
            "metricsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "pprof": {"type": bool},
            "pprofAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtsp": {"type": bool},
            "rtspAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtspsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtmp": {"type": bool},
            "rtmpAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "rtmps": {"type": bool},
            "rtmpsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "hls": {"type": bool},
            "hlsAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
            "hlsAllowOrigin": {"type": str},
            "webrtc": {"type": bool},
            "webrtcAddress": {"type": str, "pattern": r"^[0-9.:]+$"},
        }
    
        # Validate configuration keys
        unknown_keys = set(config_updates.keys()) - set(valid_config_schema.keys())
        if unknown_keys:
            error_msg = f"Unknown configuration keys: {list(unknown_keys)}"
            self._logger.error(error_msg, extra={"correlation_id": correlation_id})
            raise ValueError(error_msg)
    
        # Enhanced configuration value validation with error accumulation
        validation_errors = []
        for key, value in config_updates.items():
            schema = valid_config_schema[key]
    
            # Ensure schema is a dictionary
            if not isinstance(schema, dict):
                validation_errors.append(f"Invalid schema for {key}: expected dict, got {type(schema)}")
                continue
    
            # Type validation
            if "type" in schema and not isinstance(value, schema["type"]):
                validation_errors.append(
                    f"Invalid type for {key}: expected {schema['type']}, got {type(value)}"
                )
                continue
    
            # Value constraints validation
            if "values" in schema and value not in schema["values"]:
                validation_errors.append(
                    f"Invalid value for {key}: {value}, allowed values: {schema['values']}"
                )
    
            if (
                "min" in schema
                and isinstance(value, (int, float))
                and value < schema["min"]
            ):
                validation_errors.append(
                    f"Value for {key} too small: {value}, minimum: {schema['min']}"
                )
    
            if (
                "max" in schema
                and isinstance(value, (int, float))
                and value > schema["max"]
            ):
                validation_errors.append(
                    f"Value for {key} too large: {value}, maximum: {schema['max']}"
                )
    
            # Pattern validation for string types
            if "pattern" in schema and isinstance(value, str):
                import re
    
                if not re.match(schema["pattern"], value):
                    validation_errors.append(f"Invalid format for {key}: {value}")
    
        if validation_errors:
            error_msg = (
                f"Configuration validation failed: {'; '.join(validation_errors)}"
            )
            self._logger.error(error_msg, extra={"correlation_id": correlation_id})
            raise ValueError(error_msg)
    
        try:
            self._logger.info(
                f"Updating MediaMTX configuration: {list(config_updates.keys())}",
                extra={"correlation_id": correlation_id},
            )
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/global/patch", json=config_updates
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:1316: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - INFO - [51f93e2f] Updating MediaMTX configuration: ['logLevel']
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1311 Updating MediaMTX configuration: ['logLevel']
__ TestHealthMonitoring.test_circuit_breaker_recovery_confirmation_threshold ___

self = <tests.unit.test_mediamtx_wrapper.test_controller_health_monitoring.TestHealthMonitoring object at 0x7faac738c490>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4a70ee0>
mock_session = <Mock id='140371420450672'>

    @pytest.mark.asyncio
    async def test_circuit_breaker_recovery_confirmation_threshold(
        self, controller_fast_timers, mock_session
    ):
        """Test circuit breaker requires N consecutive successes before full reset."""
        controller = controller_fast_timers
        controller._session = mock_session
    
        # Configure for 2 consecutive successes required for recovery
        controller._health_recovery_confirmation_threshold = 2
    
        # Mock sequence: failures (trigger CB) → timeout → success → failure → success →
        # success (full recovery)
        failure_response = self._mock_response(500, text_data="Service Unavailable")
        success_response = self._mock_response(
            200, {"serverVersion": "1.0.0", "serverUptime": 1200}
        )
    
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger circuit breaker
            success_response,  # First success during recovery
            failure_response,  # Failure interrupts recovery
            success_response,  # Success again
            success_response,  # Second consecutive success - should fully recover
        ]
        mock_session.get.side_effect = responses
    
        await controller.start()
        await asyncio.sleep(0.6)  # Let health checks run through sequence
        await controller.stop()
    
        # Verify circuit breaker was activated and recovered
>       assert controller._health_state["circuit_breaker_activations"] > 0
E       assert 0 > 0

tests/unit/test_mediamtx_wrapper/test_controller_health_monitoring.py:136: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - INFO - [51f93e2f] Starting MediaMTX controller
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - INFO - [51f93e2f] MediaMTX controller started successfully
2025-08-10 12:09:44 - src.mediamtx_wrapper.controller - INFO - [28af5f20] Starting MediaMTX health monitoring loop
2025-08-10 12:09:45 - src.mediamtx_wrapper.controller - INFO - [03913242] Stopping MediaMTX controller
2025-08-10 12:09:45 - src.mediamtx_wrapper.controller - INFO - [03913242] Health monitoring loop cancelled
2025-08-10 12:09:45 - src.mediamtx_wrapper.controller - INFO - [03913242] Health monitoring loop ended - Final stats: checks=6, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=2
2025-08-10 12:09:45 - src.mediamtx_wrapper.controller - INFO - [03913242] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=6, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=2
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
_______ TestHealthMonitoring.test_recovery_confirmation_reset_on_failure _______

self = <tests.unit.test_mediamtx_wrapper.test_controller_health_monitoring.TestHealthMonitoring object at 0x7faac738cf40>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac66c9b70>
mock_session = <Mock id='140371450180128'>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7faac4d188b0>

    @pytest.mark.asyncio
    async def test_recovery_confirmation_reset_on_failure(
        self, controller_fast_timers, mock_session, caplog
    ):
        """Test recovery confirmation progress resets when failure occurs during recovery."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 3
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB timeout → success → success → failure → success
        # (restart confirmation)
        responses = [failure_response] * 4 + [
            success_response,
            success_response,
            failure_response,
            success_response,
        ] * 3
        mock_session.get.side_effect = responses
    
        with caplog.at_level("INFO"):
            await controller.start()
            await asyncio.sleep(0.8)
            await controller.stop()
    
        # Verify partial recovery logging
        log_messages = [record.message for record in caplog.records]
        improving_logs = [msg for msg in log_messages if "IMPROVING" in msg]
>       assert len(improving_logs) > 0, "Should log partial recovery progress"
E       AssertionError: Should log partial recovery progress
E       assert 0 > 0
E        +  where 0 = len([])

tests/unit/test_mediamtx_wrapper/test_controller_health_monitoring.py:169: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:45 - src.mediamtx_wrapper.controller - INFO - [03913242] Starting MediaMTX controller
2025-08-10 12:09:45 - src.mediamtx_wrapper.controller - INFO - [03913242] MediaMTX controller started successfully
2025-08-10 12:09:45 - src.mediamtx_wrapper.controller - INFO - [5a9dc35e] Starting MediaMTX health monitoring loop
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [f29706e8] Stopping MediaMTX controller
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [f29706e8] Health monitoring loop cancelled
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [f29706e8] Health monitoring loop ended - Final stats: checks=8, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [f29706e8] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=8, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
__________ TestHealthMonitoring.test_health_state_transition_logging ___________

self = <tests.unit.test_mediamtx_wrapper.test_controller_health_monitoring.TestHealthMonitoring object at 0x7faac738c6d0>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac657d300>
mock_session = <Mock id='140371448809024'>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7faac738d840>

    @pytest.mark.asyncio
    async def test_health_state_transition_logging(
        self, controller_fast_timers, mock_session, caplog
    ):
        """Test health state transitions are logged with context."""
        controller = controller_fast_timers
        controller._session = mock_session
    
        # Mock transition from failure to success
        failure_response = self._mock_response(500, text_data="Service Unavailable")
        success_response = self._mock_response(
            200, {"serverVersion": "1.0.0", "serverUptime": 1200}
        )
    
        mock_session.get.side_effect = [
            failure_response,
            success_response,
            success_response,
        ]
    
        with caplog.at_level("INFO"):
            await controller.start()
            await asyncio.sleep(0.3)  # Let health checks run
            await controller.stop()
    
        # Verify transition logging
        log_messages = [record.message for record in caplog.records]
    
        # Should see health degradation and recovery messages
        degraded_logs = [msg for msg in log_messages if "DEGRADED" in msg]
        [msg for msg in log_messages if "RECOVERED" in msg]
    
>       assert len(degraded_logs) > 0, "Should log health degradation"
E       AssertionError: Should log health degradation
E       assert 0 > 0
E        +  where 0 = len([])

tests/unit/test_mediamtx_wrapper/test_controller_health_monitoring.py:239: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [8a85d47a] Starting MediaMTX controller
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [8a85d47a] MediaMTX controller started successfully
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [ff633a3f] Starting MediaMTX health monitoring loop
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [bf5b53d1] Stopping MediaMTX controller
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [bf5b53d1] Health monitoring loop cancelled
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [bf5b53d1] Health monitoring loop ended - Final stats: checks=3, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
2025-08-10 12:09:46 - src.mediamtx_wrapper.controller - INFO - [bf5b53d1] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=3, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
_____ TestRecordingDuration.test_recording_duration_calculation_precision ______

self = <tests.unit.test_mediamtx_wrapper.test_controller_recording_duration.TestRecordingDuration object at 0x7faac74c1630>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4c6fc40>
mock_http_success = <function TestRecordingDuration.mock_http_success.<locals>._mock_response at 0x7faac498f1c0>

    @pytest.mark.asyncio
    async def test_recording_duration_calculation_precision(
        self, controller, mock_http_success
    ):
        """Test accurate duration calculation using session timestamps."""
        # Mock successful HTTP responses for start and stop
        controller._session.post = AsyncMock(return_value=mock_http_success())
    
        # Start recording and capture start time
        start_time = time.time()
>       await controller.start_recording("test_stream", duration=3600, format="mp4")

tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4c6fc40>
stream_name = 'test_stream', duration = 3600, format = 'mp4'

    async def start_recording(
        self, stream_name: str, duration: Optional[int] = None, format: str = "mp4"
    ) -> Dict[str, Any]:
        """
        Start recording for the specified stream with enhanced session management.
    
        Args:
            stream_name: Name of the stream to record
            duration: Recording duration in seconds (None for unlimited)
            format: Recording format (mp4, mkv)
    
        Returns:
            Dict containing recording session information
    
        Raises:
            ValueError: If stream does not exist or is already recording
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        if stream_name in self._recording_sessions:
            raise ValueError(f"Recording already active for stream: {stream_name}")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Validate format
        valid_formats = ["mp4", "mkv", "avi"]
        if format not in valid_formats:
            raise ValueError(
                f"Invalid format: {format}. Must be one of: {valid_formats}"
            )
    
        try:
            # Ensure recordings directory exists and is writable
            try:
                os.makedirs(self._recordings_path, exist_ok=True)
                # Test write permissions
                test_file = os.path.join(
                    self._recordings_path, f".write_test_{uuid.uuid4().hex[:8]}"
                )
                with open(test_file, "w") as f:
                    f.write("test")
                os.remove(test_file)
            except (PermissionError, OSError) as e:
                error_msg = (
                    f"Cannot write to recordings directory {self._recordings_path}: {e}"
                )
                self._logger.error(
                    error_msg,
                    extra={
                        "correlation_id": correlation_id,
                        "stream_name": stream_name,
                    },
                )
                raise ValueError(error_msg) from e
    
            # Generate recording filename with timestamp
            timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
            filename = f"{stream_name}_{timestamp}.{format}"
            record_path = os.path.join(self._recordings_path, filename)
    
            # Record start time for duration calculation
            start_time = time.time()
            start_time_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ")
    
            # Update stream configuration to enable recording
            path_config = {"record": True, "recordPath": record_path}
    
            if duration:
                path_config["recordDuration"] = duration
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/edit/{stream_name}", json=path_config
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:611: AttributeError
__________ TestRecordingDuration.test_recording_missing_file_handling __________

self = <tests.unit.test_mediamtx_wrapper.test_controller_recording_duration.TestRecordingDuration object at 0x7faac74c1a50>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac66650f0>
mock_http_success = <function TestRecordingDuration.mock_http_success.<locals>._mock_response at 0x7faac498ef80>

    @pytest.mark.asyncio
    async def test_recording_missing_file_handling(self, controller, mock_http_success):
        """Test stop_recording when file doesn't exist on disk."""
        # Setup recording session
        controller._session.post = AsyncMock(return_value=mock_http_success())
>       await controller.start_recording("test_stream", format="mp4")

tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac66650f0>
stream_name = 'test_stream', duration = None, format = 'mp4'

    async def start_recording(
        self, stream_name: str, duration: Optional[int] = None, format: str = "mp4"
    ) -> Dict[str, Any]:
        """
        Start recording for the specified stream with enhanced session management.
    
        Args:
            stream_name: Name of the stream to record
            duration: Recording duration in seconds (None for unlimited)
            format: Recording format (mp4, mkv)
    
        Returns:
            Dict containing recording session information
    
        Raises:
            ValueError: If stream does not exist or is already recording
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        if stream_name in self._recording_sessions:
            raise ValueError(f"Recording already active for stream: {stream_name}")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Validate format
        valid_formats = ["mp4", "mkv", "avi"]
        if format not in valid_formats:
            raise ValueError(
                f"Invalid format: {format}. Must be one of: {valid_formats}"
            )
    
        try:
            # Ensure recordings directory exists and is writable
            try:
                os.makedirs(self._recordings_path, exist_ok=True)
                # Test write permissions
                test_file = os.path.join(
                    self._recordings_path, f".write_test_{uuid.uuid4().hex[:8]}"
                )
                with open(test_file, "w") as f:
                    f.write("test")
                os.remove(test_file)
            except (PermissionError, OSError) as e:
                error_msg = (
                    f"Cannot write to recordings directory {self._recordings_path}: {e}"
                )
                self._logger.error(
                    error_msg,
                    extra={
                        "correlation_id": correlation_id,
                        "stream_name": stream_name,
                    },
                )
                raise ValueError(error_msg) from e
    
            # Generate recording filename with timestamp
            timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
            filename = f"{stream_name}_{timestamp}.{format}"
            record_path = os.path.join(self._recordings_path, filename)
    
            # Record start time for duration calculation
            start_time = time.time()
            start_time_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ")
    
            # Update stream configuration to enable recording
            path_config = {"record": True, "recordPath": record_path}
    
            if duration:
                path_config["recordDuration"] = duration
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/edit/{stream_name}", json=path_config
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:611: AttributeError
__________ TestRecordingDuration.test_recording_file_permission_error __________

self = <tests.unit.test_mediamtx_wrapper.test_controller_recording_duration.TestRecordingDuration object at 0x7faac74c3b20>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac66170a0>
mock_http_success = <function TestRecordingDuration.mock_http_success.<locals>._mock_response at 0x7faac498ca60>

    @pytest.mark.asyncio
    async def test_recording_file_permission_error(self, controller, mock_http_success):
        """Test handling when file exists but cannot be accessed due to permissions."""
        # Setup recording session
        controller._session.post = AsyncMock(return_value=mock_http_success())
>       await controller.start_recording("test_stream", format="mp4")

tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py:103: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac66170a0>
stream_name = 'test_stream', duration = None, format = 'mp4'

    async def start_recording(
        self, stream_name: str, duration: Optional[int] = None, format: str = "mp4"
    ) -> Dict[str, Any]:
        """
        Start recording for the specified stream with enhanced session management.
    
        Args:
            stream_name: Name of the stream to record
            duration: Recording duration in seconds (None for unlimited)
            format: Recording format (mp4, mkv)
    
        Returns:
            Dict containing recording session information
    
        Raises:
            ValueError: If stream does not exist or is already recording
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        if stream_name in self._recording_sessions:
            raise ValueError(f"Recording already active for stream: {stream_name}")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Validate format
        valid_formats = ["mp4", "mkv", "avi"]
        if format not in valid_formats:
            raise ValueError(
                f"Invalid format: {format}. Must be one of: {valid_formats}"
            )
    
        try:
            # Ensure recordings directory exists and is writable
            try:
                os.makedirs(self._recordings_path, exist_ok=True)
                # Test write permissions
                test_file = os.path.join(
                    self._recordings_path, f".write_test_{uuid.uuid4().hex[:8]}"
                )
                with open(test_file, "w") as f:
                    f.write("test")
                os.remove(test_file)
            except (PermissionError, OSError) as e:
                error_msg = (
                    f"Cannot write to recordings directory {self._recordings_path}: {e}"
                )
                self._logger.error(
                    error_msg,
                    extra={
                        "correlation_id": correlation_id,
                        "stream_name": stream_name,
                    },
                )
                raise ValueError(error_msg) from e
    
            # Generate recording filename with timestamp
            timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
            filename = f"{stream_name}_{timestamp}.{format}"
            record_path = os.path.join(self._recordings_path, filename)
    
            # Record start time for duration calculation
            start_time = time.time()
            start_time_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ")
    
            # Update stream configuration to enable recording
            path_config = {"record": True, "recordPath": record_path}
    
            if duration:
                path_config["recordDuration"] = duration
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/edit/{stream_name}", json=path_config
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:611: AttributeError
___________ TestRecordingDuration.test_recording_session_management ____________

self = <tests.unit.test_mediamtx_wrapper.test_controller_recording_duration.TestRecordingDuration object at 0x7faac74c0550>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac654c100>
mock_http_success = <function TestRecordingDuration.mock_http_success.<locals>._mock_response at 0x7faac4adc280>

    @pytest.mark.asyncio
    async def test_recording_session_management(self, controller, mock_http_success):
        """Test recording session tracking and cleanup."""
        controller._session.post = AsyncMock(return_value=mock_http_success())
    
        # Start recording - should create session
>       await controller.start_recording("test_stream", format="mp4")

tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac654c100>
stream_name = 'test_stream', duration = None, format = 'mp4'

    async def start_recording(
        self, stream_name: str, duration: Optional[int] = None, format: str = "mp4"
    ) -> Dict[str, Any]:
        """
        Start recording for the specified stream with enhanced session management.
    
        Args:
            stream_name: Name of the stream to record
            duration: Recording duration in seconds (None for unlimited)
            format: Recording format (mp4, mkv)
    
        Returns:
            Dict containing recording session information
    
        Raises:
            ValueError: If stream does not exist or is already recording
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        if stream_name in self._recording_sessions:
            raise ValueError(f"Recording already active for stream: {stream_name}")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Validate format
        valid_formats = ["mp4", "mkv", "avi"]
        if format not in valid_formats:
            raise ValueError(
                f"Invalid format: {format}. Must be one of: {valid_formats}"
            )
    
        try:
            # Ensure recordings directory exists and is writable
            try:
                os.makedirs(self._recordings_path, exist_ok=True)
                # Test write permissions
                test_file = os.path.join(
                    self._recordings_path, f".write_test_{uuid.uuid4().hex[:8]}"
                )
                with open(test_file, "w") as f:
                    f.write("test")
                os.remove(test_file)
            except (PermissionError, OSError) as e:
                error_msg = (
                    f"Cannot write to recordings directory {self._recordings_path}: {e}"
                )
                self._logger.error(
                    error_msg,
                    extra={
                        "correlation_id": correlation_id,
                        "stream_name": stream_name,
                    },
                )
                raise ValueError(error_msg) from e
    
            # Generate recording filename with timestamp
            timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
            filename = f"{stream_name}_{timestamp}.{format}"
            record_path = os.path.join(self._recordings_path, filename)
    
            # Record start time for duration calculation
            start_time = time.time()
            start_time_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ")
    
            # Update stream configuration to enable recording
            path_config = {"record": True, "recordPath": record_path}
    
            if duration:
                path_config["recordDuration"] = duration
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/edit/{stream_name}", json=path_config
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:611: AttributeError
______ TestRecordingDuration.test_recording_api_failure_preserves_session ______

self = <tests.unit.test_mediamtx_wrapper.test_controller_recording_duration.TestRecordingDuration object at 0x7faac74c3130>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4944a90>

    @pytest.mark.asyncio
    async def test_recording_api_failure_preserves_session(self, controller):
        """Test that API failures during stop don't lose session data for retry."""
        # Start recording successfully
        success_response = Mock()
        success_response.status = 200
        controller._session.post = AsyncMock(return_value=success_response)
>       await controller.start_recording("test_stream", format="mp4")

tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4944a90>
stream_name = 'test_stream', duration = None, format = 'mp4'

    async def start_recording(
        self, stream_name: str, duration: Optional[int] = None, format: str = "mp4"
    ) -> Dict[str, Any]:
        """
        Start recording for the specified stream with enhanced session management.
    
        Args:
            stream_name: Name of the stream to record
            duration: Recording duration in seconds (None for unlimited)
            format: Recording format (mp4, mkv)
    
        Returns:
            Dict containing recording session information
    
        Raises:
            ValueError: If stream does not exist or is already recording
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        if stream_name in self._recording_sessions:
            raise ValueError(f"Recording already active for stream: {stream_name}")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Validate format
        valid_formats = ["mp4", "mkv", "avi"]
        if format not in valid_formats:
            raise ValueError(
                f"Invalid format: {format}. Must be one of: {valid_formats}"
            )
    
        try:
            # Ensure recordings directory exists and is writable
            try:
                os.makedirs(self._recordings_path, exist_ok=True)
                # Test write permissions
                test_file = os.path.join(
                    self._recordings_path, f".write_test_{uuid.uuid4().hex[:8]}"
                )
                with open(test_file, "w") as f:
                    f.write("test")
                os.remove(test_file)
            except (PermissionError, OSError) as e:
                error_msg = (
                    f"Cannot write to recordings directory {self._recordings_path}: {e}"
                )
                self._logger.error(
                    error_msg,
                    extra={
                        "correlation_id": correlation_id,
                        "stream_name": stream_name,
                    },
                )
                raise ValueError(error_msg) from e
    
            # Generate recording filename with timestamp
            timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
            filename = f"{stream_name}_{timestamp}.{format}"
            record_path = os.path.join(self._recordings_path, filename)
    
            # Record start time for duration calculation
            start_time = time.time()
            start_time_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ")
    
            # Update stream configuration to enable recording
            path_config = {"record": True, "recordPath": record_path}
    
            if duration:
                path_config["recordDuration"] = duration
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/edit/{stream_name}", json=path_config
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:611: AttributeError
__________ TestRecordingDuration.test_recording_duplicate_start_error __________

self = <tests.unit.test_mediamtx_wrapper.test_controller_recording_duration.TestRecordingDuration object at 0x7faac74c2890>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d0fb20>
mock_http_success = <function TestRecordingDuration.mock_http_success.<locals>._mock_response at 0x7faac4adc5e0>

    @pytest.mark.asyncio
    async def test_recording_duplicate_start_error(self, controller, mock_http_success):
        """Test error when trying to start recording on already recording stream."""
        controller._session.post = AsyncMock(return_value=mock_http_success())
    
        # Start first recording
>       await controller.start_recording("test_stream", format="mp4")

tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py:194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d0fb20>
stream_name = 'test_stream', duration = None, format = 'mp4'

    async def start_recording(
        self, stream_name: str, duration: Optional[int] = None, format: str = "mp4"
    ) -> Dict[str, Any]:
        """
        Start recording for the specified stream with enhanced session management.
    
        Args:
            stream_name: Name of the stream to record
            duration: Recording duration in seconds (None for unlimited)
            format: Recording format (mp4, mkv)
    
        Returns:
            Dict containing recording session information
    
        Raises:
            ValueError: If stream does not exist or is already recording
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        if stream_name in self._recording_sessions:
            raise ValueError(f"Recording already active for stream: {stream_name}")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Validate format
        valid_formats = ["mp4", "mkv", "avi"]
        if format not in valid_formats:
            raise ValueError(
                f"Invalid format: {format}. Must be one of: {valid_formats}"
            )
    
        try:
            # Ensure recordings directory exists and is writable
            try:
                os.makedirs(self._recordings_path, exist_ok=True)
                # Test write permissions
                test_file = os.path.join(
                    self._recordings_path, f".write_test_{uuid.uuid4().hex[:8]}"
                )
                with open(test_file, "w") as f:
                    f.write("test")
                os.remove(test_file)
            except (PermissionError, OSError) as e:
                error_msg = (
                    f"Cannot write to recordings directory {self._recordings_path}: {e}"
                )
                self._logger.error(
                    error_msg,
                    extra={
                        "correlation_id": correlation_id,
                        "stream_name": stream_name,
                    },
                )
                raise ValueError(error_msg) from e
    
            # Generate recording filename with timestamp
            timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
            filename = f"{stream_name}_{timestamp}.{format}"
            record_path = os.path.join(self._recordings_path, filename)
    
            # Record start time for duration calculation
            start_time = time.time()
            start_time_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ")
    
            # Update stream configuration to enable recording
            path_config = {"record": True, "recordPath": record_path}
    
            if duration:
                path_config["recordDuration"] = duration
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/edit/{stream_name}", json=path_config
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:611: AttributeError
____________ TestRecordingDuration.test_recording_format_validation ____________

self = <tests.unit.test_mediamtx_wrapper.test_controller_recording_duration.TestRecordingDuration object at 0x7faac74c2f20>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4a900a0>

    @pytest.mark.asyncio
    async def test_recording_format_validation(self, controller):
        """Test validation of recording format parameter."""
        # Test invalid format
        with pytest.raises(ValueError, match="Invalid format.*Must be one of"):
            await controller.start_recording("test_stream", format="invalid")
    
        # Test valid formats
        valid_formats = ["mp4", "mkv", "avi"]
        for format_type in valid_formats:
            # This would normally require mocking the HTTP call
            # but we're just testing the validation doesn't raise
            try:
                controller._session = Mock()
                success_response = Mock()
                success_response.status = 200
                controller._session.post = AsyncMock(return_value=success_response)
    
>               await controller.start_recording(
                    f"test_stream_{format_type}", format=format_type
                )

tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4a900a0>
stream_name = 'test_stream_mp4', duration = None, format = 'mp4'

    async def start_recording(
        self, stream_name: str, duration: Optional[int] = None, format: str = "mp4"
    ) -> Dict[str, Any]:
        """
        Start recording for the specified stream with enhanced session management.
    
        Args:
            stream_name: Name of the stream to record
            duration: Recording duration in seconds (None for unlimited)
            format: Recording format (mp4, mkv)
    
        Returns:
            Dict containing recording session information
    
        Raises:
            ValueError: If stream does not exist or is already recording
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        if stream_name in self._recording_sessions:
            raise ValueError(f"Recording already active for stream: {stream_name}")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        # Validate format
        valid_formats = ["mp4", "mkv", "avi"]
        if format not in valid_formats:
            raise ValueError(
                f"Invalid format: {format}. Must be one of: {valid_formats}"
            )
    
        try:
            # Ensure recordings directory exists and is writable
            try:
                os.makedirs(self._recordings_path, exist_ok=True)
                # Test write permissions
                test_file = os.path.join(
                    self._recordings_path, f".write_test_{uuid.uuid4().hex[:8]}"
                )
                with open(test_file, "w") as f:
                    f.write("test")
                os.remove(test_file)
            except (PermissionError, OSError) as e:
                error_msg = (
                    f"Cannot write to recordings directory {self._recordings_path}: {e}"
                )
                self._logger.error(
                    error_msg,
                    extra={
                        "correlation_id": correlation_id,
                        "stream_name": stream_name,
                    },
                )
                raise ValueError(error_msg) from e
    
            # Generate recording filename with timestamp
            timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
            filename = f"{stream_name}_{timestamp}.{format}"
            record_path = os.path.join(self._recordings_path, filename)
    
            # Record start time for duration calculation
            start_time = time.time()
            start_time_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ")
    
            # Update stream configuration to enable recording
            path_config = {"record": True, "recordPath": record_path}
    
            if duration:
                path_config["recordDuration"] = duration
    
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/edit/{stream_name}", json=path_config
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:611: AttributeError
_________ TestSnapshotCapture.test_snapshot_process_cleanup_on_timeout _________

self = <tests.unit.test_mediamtx_wrapper.test_controller_snapshot_capture.TestSnapshotCapture object at 0x7faac7485b40>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac65a66e0>

    @pytest.mark.asyncio
    async def test_snapshot_process_cleanup_on_timeout(self, controller):
        """Test robust process cleanup when FFmpeg times out."""
        # Mock FFmpeg process that hangs indefinitely
        mock_process = Mock()
        mock_process.returncode = None  # Process still running
        mock_process.communicate = AsyncMock(side_effect=asyncio.TimeoutError())
        mock_process.terminate = Mock()
        mock_process.kill = Mock()
        mock_process.wait = AsyncMock(
            side_effect=asyncio.TimeoutError()
        )  # Doesn't respond to signals
    
        with patch("asyncio.create_subprocess_exec", return_value=mock_process):
            result = await controller.take_snapshot("test_stream", "test_snapshot.jpg")
    
            # Verify graceful termination then force kill was attempted
>           mock_process.terminate.assert_called_once()

tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Mock name='mock.terminate' id='140371448983904'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'terminate' to have been called once. Called 0 times.

/usr/lib/python3.10/unittest/mock.py:908: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - ERROR - [1639c06e] Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite 'filename' in LogRecord"
------------------------------ Captured log call -------------------------------
ERROR    src.mediamtx_wrapper.controller:controller.py:1007 Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite 'filename' in LogRecord"
__________ TestSnapshotCapture.test_snapshot_file_size_error_handling __________

self = <tests.unit.test_mediamtx_wrapper.test_controller_snapshot_capture.TestSnapshotCapture object at 0x7faac7485d80>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4acec20>

    @pytest.mark.asyncio
    async def test_snapshot_file_size_error_handling(self, controller):
        """Test handling when file exists but size cannot be determined."""
        # Mock successful FFmpeg execution
        mock_process = Mock()
        mock_process.returncode = 0
        mock_process.communicate = AsyncMock(return_value=(b"success", b""))
    
        # Mock file that exists but raises OSError on getsize
        with (
            patch("asyncio.create_subprocess_exec", return_value=mock_process),
            patch("os.path.exists", return_value=True),
            patch("os.path.getsize", side_effect=OSError("Permission denied")),
        ):
    
            result = await controller.take_snapshot("test_stream", "test_snapshot.jpg")
    
            # Verify successful completion with warning about file size
>           assert result["status"] == "completed"
E           AssertionError: assert 'failed' == 'completed'
E             
E             - completed
E             + failed

tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py:84: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - ERROR - [1639c06e] Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite 'filename' in LogRecord"
------------------------------ Captured log call -------------------------------
ERROR    src.mediamtx_wrapper.controller:controller.py:1007 Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite 'filename' in LogRecord"
__________ TestSnapshotCapture.test_snapshot_ffmpeg_nonzero_exit_code __________

self = <tests.unit.test_mediamtx_wrapper.test_controller_snapshot_capture.TestSnapshotCapture object at 0x7faac7486d10>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4c9aad0>

    @pytest.mark.asyncio
    async def test_snapshot_ffmpeg_nonzero_exit_code(self, controller):
        """Test handling when FFmpeg exits with error code."""
        # Mock FFmpeg process that fails
        mock_process = Mock()
        mock_process.returncode = 1  # Error exit code
        mock_process.communicate = AsyncMock(return_value=(b"", b"Input/output error"))
    
        with (
            patch("asyncio.create_subprocess_exec", return_value=mock_process),
            patch("os.path.exists", return_value=False),
        ):  # No output file created
    
            result = await controller.take_snapshot("test_stream", "test_snapshot.jpg")
    
            # Verify error is properly captured and reported
            assert result["status"] == "failed"
>           assert "FFmpeg capture failed" in result["error"]
E           assert 'FFmpeg capture failed' in 'Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite \'filename\' in LogRecord"'

tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py:121: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - ERROR - [1639c06e] Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite 'filename' in LogRecord"
------------------------------ Captured log call -------------------------------
ERROR    src.mediamtx_wrapper.controller:controller.py:1007 Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite 'filename' in LogRecord"
_______ TestSnapshotCapture.test_snapshot_success_with_accurate_metadata _______

self = <tests.unit.test_mediamtx_wrapper.test_controller_snapshot_capture.TestSnapshotCapture object at 0x7faac7487220>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4ad6b00>

    @pytest.mark.asyncio
    async def test_snapshot_success_with_accurate_metadata(self, controller):
        """Test successful snapshot capture returns accurate metadata."""
        # Mock successful FFmpeg execution
        mock_process = Mock()
        mock_process.returncode = 0
        mock_process.communicate = AsyncMock(return_value=(b"success", b""))
    
        test_file_size = 12345
        test_file_path = os.path.join(controller._snapshots_path, "test_snapshot.jpg")
    
        with (
            patch("asyncio.create_subprocess_exec", return_value=mock_process),
            patch("os.path.exists", return_value=True),
            patch("os.path.getsize", return_value=test_file_size),
            patch("os.makedirs"),
        ):
    
            result = await controller.take_snapshot("test_stream", "test_snapshot.jpg")
    
            # Verify accurate metadata
>           assert result["status"] == "completed"
E           AssertionError: assert 'failed' == 'completed'
E             
E             - completed
E             + failed

tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py:145: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - ERROR - [1639c06e] Cannot write to snapshots directory /tmp/tmp8ma3f8ow/snapshots: [Errno 2] No such file or directory: '/tmp/tmp8ma3f8ow/snapshots/.write_test_eac32117'
------------------------------ Captured log call -------------------------------
ERROR    src.mediamtx_wrapper.controller:controller.py:854 Cannot write to snapshots directory /tmp/tmp8ma3f8ow/snapshots: [Errno 2] No such file or directory: '/tmp/tmp8ma3f8ow/snapshots/.write_test_eac32117'
__________ TestSnapshotCapture.test_snapshot_process_creation_timeout __________

self = <tests.unit.test_mediamtx_wrapper.test_controller_snapshot_capture.TestSnapshotCapture object at 0x7faac7487670>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac666da80>

    @pytest.mark.asyncio
    async def test_snapshot_process_creation_timeout(self, controller):
        """Test timeout during FFmpeg process creation."""
        # Mock process creation that times out
        with patch(
            "asyncio.create_subprocess_exec", side_effect=asyncio.TimeoutError()
        ):
            result = await controller.take_snapshot("test_stream", "test_snapshot.jpg")
    
            # Verify timeout is handled gracefully
            assert result["status"] == "failed"
>           assert "timeout" in result["error"].lower()
E           assert 'timeout' in 'failed to capture snapshot for test_stream (no_cleanup_needed): "attempt to overwrite \'filename\' in logrecord"'
E            +  where 'failed to capture snapshot for test_stream (no_cleanup_needed): "attempt to overwrite \'filename\' in logrecord"' = <built-in method lower of str object at 0x7faac4c58f30>()
E            +    where <built-in method lower of str object at 0x7faac4c58f30> = 'Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite \'filename\' in LogRecord"'.lower

tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py:162: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - ERROR - [1639c06e] Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite 'filename' in LogRecord"
------------------------------ Captured log call -------------------------------
ERROR    src.mediamtx_wrapper.controller:controller.py:1007 Failed to capture snapshot for test_stream (no_cleanup_needed): "Attempt to overwrite 'filename' in LogRecord"
_______________ TestStreamOperations.test_create_stream_success ________________

self = <tests.unit.test_mediamtx_wrapper.test_controller_stream_operations.TestStreamOperations object at 0x7faac7404670>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4cc6260>
sample_stream_config = StreamConfig(name='test_stream', source='/dev/video0', record=False, record_path=None)

    @pytest.mark.asyncio
    async def test_create_stream_success(self, controller, sample_stream_config):
        """Test successful stream creation returns correct URLs."""
        # Mock successful response
        success_response = self._mock_response(200)
        controller._session.post = AsyncMock(return_value=success_response)
    
        # Mock get_stream_status to return stream doesn't exist (for idempotency check)
        controller.get_stream_status = AsyncMock(
            side_effect=ValueError("Stream not found")
        )
    
>       result = await controller.create_stream(sample_stream_config)

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4cc6260>
stream_config = StreamConfig(name='test_stream', source='/dev/video0', record=False, record_path=None)

    async def create_stream(self, stream_config: StreamConfig) -> Dict[str, str]:
        """
        Create a new stream path in MediaMTX with enhanced idempotent behavior.
    
        Args:
            stream_config: Stream configuration parameters
    
        Returns:
            Dict containing stream URLs for different protocols
    
        Raises:
            ValueError: If stream configuration is invalid
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_config.name or not stream_config.source:
            raise ValueError("Stream name and source are required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        self._logger.info(
            f"Creating stream path: {stream_config.name} from {stream_config.source}",
            extra={"correlation_id": correlation_id, "stream_name": stream_config.name},
        )
    
        try:
            # Enhanced idempotent behavior - check if stream already exists
            try:
                existing_stream = await self.get_stream_status(stream_config.name)
                if existing_stream.get("name") == stream_config.name:
                    self._logger.info(
                        f"Stream path already exists, returning existing URLs: {stream_config.name}",
                        extra={
                            "correlation_id": correlation_id,
                            "stream_name": stream_config.name,
                        },
                    )
                    return self._generate_stream_urls(stream_config.name)
            except ValueError:
                # Stream doesn't exist, proceed with creation
                pass
    
            # Create MediaMTX path configuration
            path_config = {
                "source": stream_config.source,
                "sourceProtocol": "automatic",
                "record": stream_config.record,
            }
    
            if stream_config.record and stream_config.record_path:
                path_config["recordPath"] = stream_config.record_path
    
            # Add stream path via MediaMTX API
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/add/{stream_config.name}",
                json=path_config,
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:407: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Creating stream path: test_stream from /dev/video0
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:374 Creating stream path: test_stream from /dev/video0
_______ TestStreamOperations.test_create_stream_conflict_409_idempotent ________

self = <tests.unit.test_mediamtx_wrapper.test_controller_stream_operations.TestStreamOperations object at 0x7faac7405360>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac738ebf0>
sample_stream_config = StreamConfig(name='test_stream', source='/dev/video0', record=False, record_path=None)

    @pytest.mark.asyncio
    async def test_create_stream_conflict_409_idempotent(
        self, controller, sample_stream_config
    ):
        """Test 409 conflict response is handled idempotently."""
        # Mock get_stream_status to indicate stream doesn't exist initially
        controller.get_stream_status = AsyncMock(
            side_effect=ValueError("Stream not found")
        )
    
        # Mock 409 conflict response from create call
        conflict_response = self._mock_response(409, text_data="Path already exists")
        controller._session.post = AsyncMock(return_value=conflict_response)
    
>       result = await controller.create_stream(sample_stream_config)

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py:103: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac738ebf0>
stream_config = StreamConfig(name='test_stream', source='/dev/video0', record=False, record_path=None)

    async def create_stream(self, stream_config: StreamConfig) -> Dict[str, str]:
        """
        Create a new stream path in MediaMTX with enhanced idempotent behavior.
    
        Args:
            stream_config: Stream configuration parameters
    
        Returns:
            Dict containing stream URLs for different protocols
    
        Raises:
            ValueError: If stream configuration is invalid
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_config.name or not stream_config.source:
            raise ValueError("Stream name and source are required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        self._logger.info(
            f"Creating stream path: {stream_config.name} from {stream_config.source}",
            extra={"correlation_id": correlation_id, "stream_name": stream_config.name},
        )
    
        try:
            # Enhanced idempotent behavior - check if stream already exists
            try:
                existing_stream = await self.get_stream_status(stream_config.name)
                if existing_stream.get("name") == stream_config.name:
                    self._logger.info(
                        f"Stream path already exists, returning existing URLs: {stream_config.name}",
                        extra={
                            "correlation_id": correlation_id,
                            "stream_name": stream_config.name,
                        },
                    )
                    return self._generate_stream_urls(stream_config.name)
            except ValueError:
                # Stream doesn't exist, proceed with creation
                pass
    
            # Create MediaMTX path configuration
            path_config = {
                "source": stream_config.source,
                "sourceProtocol": "automatic",
                "record": stream_config.record,
            }
    
            if stream_config.record and stream_config.record_path:
                path_config["recordPath"] = stream_config.record_path
    
            # Add stream path via MediaMTX API
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/add/{stream_config.name}",
                json=path_config,
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:407: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Creating stream path: test_stream from /dev/video0
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:374 Creating stream path: test_stream from /dev/video0
________ TestStreamOperations.test_create_stream_api_error_with_context ________

self = <tests.unit.test_mediamtx_wrapper.test_controller_stream_operations.TestStreamOperations object at 0x7faac7405120>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac7406da0>
sample_stream_config = StreamConfig(name='test_stream', source='/dev/video0', record=False, record_path=None)

    @pytest.mark.asyncio
    async def test_create_stream_api_error_with_context(
        self, controller, sample_stream_config
    ):
        """Test API error includes detailed context information."""
        # Mock get_stream_status to indicate stream doesn't exist
        controller.get_stream_status = AsyncMock(
            side_effect=ValueError("Stream not found")
        )
    
        # Mock API error response
        error_response = self._mock_response(500, text_data="Internal Server Error")
        controller._session.post = AsyncMock(return_value=error_response)
    
        with pytest.raises(ConnectionError) as exc_info:
>           await controller.create_stream(sample_stream_config)

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac7406da0>
stream_config = StreamConfig(name='test_stream', source='/dev/video0', record=False, record_path=None)

    async def create_stream(self, stream_config: StreamConfig) -> Dict[str, str]:
        """
        Create a new stream path in MediaMTX with enhanced idempotent behavior.
    
        Args:
            stream_config: Stream configuration parameters
    
        Returns:
            Dict containing stream URLs for different protocols
    
        Raises:
            ValueError: If stream configuration is invalid
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_config.name or not stream_config.source:
            raise ValueError("Stream name and source are required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        self._logger.info(
            f"Creating stream path: {stream_config.name} from {stream_config.source}",
            extra={"correlation_id": correlation_id, "stream_name": stream_config.name},
        )
    
        try:
            # Enhanced idempotent behavior - check if stream already exists
            try:
                existing_stream = await self.get_stream_status(stream_config.name)
                if existing_stream.get("name") == stream_config.name:
                    self._logger.info(
                        f"Stream path already exists, returning existing URLs: {stream_config.name}",
                        extra={
                            "correlation_id": correlation_id,
                            "stream_name": stream_config.name,
                        },
                    )
                    return self._generate_stream_urls(stream_config.name)
            except ValueError:
                # Stream doesn't exist, proceed with creation
                pass
    
            # Create MediaMTX path configuration
            path_config = {
                "source": stream_config.source,
                "sourceProtocol": "automatic",
                "record": stream_config.record,
            }
    
            if stream_config.record and stream_config.record_path:
                path_config["recordPath"] = stream_config.record_path
    
            # Add stream path via MediaMTX API
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/add/{stream_config.name}",
                json=path_config,
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:407: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Creating stream path: test_stream from /dev/video0
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:374 Creating stream path: test_stream from /dev/video0
____________ TestStreamOperations.test_create_stream_network_error _____________

self = <tests.unit.test_mediamtx_wrapper.test_controller_stream_operations.TestStreamOperations object at 0x7faac7405b10>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac6687e50>
sample_stream_config = StreamConfig(name='test_stream', source='/dev/video0', record=False, record_path=None)

    @pytest.mark.asyncio
    async def test_create_stream_network_error(self, controller, sample_stream_config):
        """Test network connectivity error handling."""
        # Mock get_stream_status to indicate stream doesn't exist
        controller.get_stream_status = AsyncMock(
            side_effect=ValueError("Stream not found")
        )
    
        # Mock network error
        controller._session.post = AsyncMock(
            side_effect=aiohttp.ClientError("Connection refused")
        )
    
        with pytest.raises(ConnectionError, match="MediaMTX unreachable"):
>           await controller.create_stream(sample_stream_config)

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac6687e50>
stream_config = StreamConfig(name='test_stream', source='/dev/video0', record=False, record_path=None)

    async def create_stream(self, stream_config: StreamConfig) -> Dict[str, str]:
        """
        Create a new stream path in MediaMTX with enhanced idempotent behavior.
    
        Args:
            stream_config: Stream configuration parameters
    
        Returns:
            Dict containing stream URLs for different protocols
    
        Raises:
            ValueError: If stream configuration is invalid
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_config.name or not stream_config.source:
            raise ValueError("Stream name and source are required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        self._logger.info(
            f"Creating stream path: {stream_config.name} from {stream_config.source}",
            extra={"correlation_id": correlation_id, "stream_name": stream_config.name},
        )
    
        try:
            # Enhanced idempotent behavior - check if stream already exists
            try:
                existing_stream = await self.get_stream_status(stream_config.name)
                if existing_stream.get("name") == stream_config.name:
                    self._logger.info(
                        f"Stream path already exists, returning existing URLs: {stream_config.name}",
                        extra={
                            "correlation_id": correlation_id,
                            "stream_name": stream_config.name,
                        },
                    )
                    return self._generate_stream_urls(stream_config.name)
            except ValueError:
                # Stream doesn't exist, proceed with creation
                pass
    
            # Create MediaMTX path configuration
            path_config = {
                "source": stream_config.source,
                "sourceProtocol": "automatic",
                "record": stream_config.record,
            }
    
            if stream_config.record and stream_config.record_path:
                path_config["recordPath"] = stream_config.record_path
    
            # Add stream path via MediaMTX API
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/add/{stream_config.name}",
                json=path_config,
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:407: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Creating stream path: test_stream from /dev/video0
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:374 Creating stream path: test_stream from /dev/video0
_______________ TestStreamOperations.test_delete_stream_success ________________

self = <tests.unit.test_mediamtx_wrapper.test_controller_stream_operations.TestStreamOperations object at 0x7faac74d8d90>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d211b0>

    @pytest.mark.asyncio
    async def test_delete_stream_success(self, controller):
        """Test successful stream deletion."""
        # Mock successful deletion response
        success_response = self._mock_response(200)
        controller._session.post = AsyncMock(return_value=success_response)
    
>       result = await controller.delete_stream("test_stream")

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d211b0>
stream_name = 'test_stream'

    async def delete_stream(self, stream_name: str) -> bool:
        """
        Delete a stream path from MediaMTX with enhanced error handling.
    
        Args:
            stream_name: Name of the stream to delete
    
        Returns:
            True if stream was deleted successfully or didn't exist
    
        Raises:
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        self._logger.info(
            f"Deleting stream path: {stream_name}",
            extra={"correlation_id": correlation_id, "stream_name": stream_name},
        )
    
        try:
            # Delete stream path via MediaMTX API
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/delete/{stream_name}"
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:491: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Deleting stream path: test_stream
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:484 Deleting stream path: test_stream
____________ TestStreamOperations.test_delete_stream_idempotent_404 ____________

self = <tests.unit.test_mediamtx_wrapper.test_controller_stream_operations.TestStreamOperations object at 0x7faac74dba60>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d0c460>

    @pytest.mark.asyncio
    async def test_delete_stream_idempotent_404(self, controller):
        """Test 404 response is handled idempotently (stream already deleted)."""
        # Mock 404 not found response
        not_found_response = self._mock_response(404, text_data="Path not found")
        controller._session.post = AsyncMock(return_value=not_found_response)
    
>       result = await controller.delete_stream("nonexistent_stream")

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d0c460>
stream_name = 'nonexistent_stream'

    async def delete_stream(self, stream_name: str) -> bool:
        """
        Delete a stream path from MediaMTX with enhanced error handling.
    
        Args:
            stream_name: Name of the stream to delete
    
        Returns:
            True if stream was deleted successfully or didn't exist
    
        Raises:
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        self._logger.info(
            f"Deleting stream path: {stream_name}",
            extra={"correlation_id": correlation_id, "stream_name": stream_name},
        )
    
        try:
            # Delete stream path via MediaMTX API
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/delete/{stream_name}"
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:491: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Deleting stream path: nonexistent_stream
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:484 Deleting stream path: nonexistent_stream
______________ TestStreamOperations.test_delete_stream_api_error _______________

self = <tests.unit.test_mediamtx_wrapper.test_controller_stream_operations.TestStreamOperations object at 0x7faac74db0d0>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d191b0>

    @pytest.mark.asyncio
    async def test_delete_stream_api_error(self, controller):
        """Test API error during deletion."""
        # Mock API error response
        error_response = self._mock_response(500, text_data="Internal Server Error")
        controller._session.post = AsyncMock(return_value=error_response)
    
>       result = await controller.delete_stream("test_stream")

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d191b0>
stream_name = 'test_stream'

    async def delete_stream(self, stream_name: str) -> bool:
        """
        Delete a stream path from MediaMTX with enhanced error handling.
    
        Args:
            stream_name: Name of the stream to delete
    
        Returns:
            True if stream was deleted successfully or didn't exist
    
        Raises:
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        self._logger.info(
            f"Deleting stream path: {stream_name}",
            extra={"correlation_id": correlation_id, "stream_name": stream_name},
        )
    
        try:
            # Delete stream path via MediaMTX API
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/delete/{stream_name}"
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:491: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Deleting stream path: test_stream
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:484 Deleting stream path: test_stream
____________ TestStreamOperations.test_delete_stream_network_error _____________

self = <tests.unit.test_mediamtx_wrapper.test_controller_stream_operations.TestStreamOperations object at 0x7faac74d8550>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac65c3640>

    @pytest.mark.asyncio
    async def test_delete_stream_network_error(self, controller):
        """Test network error during deletion."""
        # Mock network error
        controller._session.post = AsyncMock(
            side_effect=aiohttp.ClientError("Connection refused")
        )
    
        with pytest.raises(ConnectionError, match="MediaMTX unreachable"):
>           await controller.delete_stream("test_stream")

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac65c3640>
stream_name = 'test_stream'

    async def delete_stream(self, stream_name: str) -> bool:
        """
        Delete a stream path from MediaMTX with enhanced error handling.
    
        Args:
            stream_name: Name of the stream to delete
    
        Returns:
            True if stream was deleted successfully or didn't exist
    
        Raises:
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_name:
            raise ValueError("Stream name is required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        self._logger.info(
            f"Deleting stream path: {stream_name}",
            extra={"correlation_id": correlation_id, "stream_name": stream_name},
        )
    
        try:
            # Delete stream path via MediaMTX API
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/delete/{stream_name}"
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:491: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Deleting stream path: test_stream
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:484 Deleting stream path: test_stream
____________ TestStreamOperations.test_stream_config_with_recording ____________

self = <tests.unit.test_mediamtx_wrapper.test_controller_stream_operations.TestStreamOperations object at 0x7faac74d98a0>
controller = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac660f640>

    @pytest.mark.asyncio
    async def test_stream_config_with_recording(self, controller):
        """Test stream configuration with recording enabled."""
        # Mock get_stream_status to indicate stream doesn't exist
        controller.get_stream_status = AsyncMock(
            side_effect=ValueError("Stream not found")
        )
    
        # Mock successful response
        success_response = self._mock_response(200)
        controller._session.post = AsyncMock(return_value=success_response)
    
        recording_config = StreamConfig(
            name="recording_stream",
            source="/dev/video1",
            record=True,
            record_path="/tmp/recordings/test.mp4",
        )
    
>       await controller.create_stream(recording_config)

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac660f640>
stream_config = StreamConfig(name='recording_stream', source='/dev/video1', record=True, record_path='/tmp/recordings/test.mp4')

    async def create_stream(self, stream_config: StreamConfig) -> Dict[str, str]:
        """
        Create a new stream path in MediaMTX with enhanced idempotent behavior.
    
        Args:
            stream_config: Stream configuration parameters
    
        Returns:
            Dict containing stream URLs for different protocols
    
        Raises:
            ValueError: If stream configuration is invalid
            ConnectionError: If MediaMTX is unreachable
        """
        if not self._session:
            raise ConnectionError("MediaMTX controller not started")
    
        if not stream_config.name or not stream_config.source:
            raise ValueError("Stream name and source are required")
    
        correlation_id = get_correlation_id() or str(uuid.uuid4())[:8]
        set_correlation_id(correlation_id)
    
        self._logger.info(
            f"Creating stream path: {stream_config.name} from {stream_config.source}",
            extra={"correlation_id": correlation_id, "stream_name": stream_config.name},
        )
    
        try:
            # Enhanced idempotent behavior - check if stream already exists
            try:
                existing_stream = await self.get_stream_status(stream_config.name)
                if existing_stream.get("name") == stream_config.name:
                    self._logger.info(
                        f"Stream path already exists, returning existing URLs: {stream_config.name}",
                        extra={
                            "correlation_id": correlation_id,
                            "stream_name": stream_config.name,
                        },
                    )
                    return self._generate_stream_urls(stream_config.name)
            except ValueError:
                # Stream doesn't exist, proceed with creation
                pass
    
            # Create MediaMTX path configuration
            path_config = {
                "source": stream_config.source,
                "sourceProtocol": "automatic",
                "record": stream_config.record,
            }
    
            if stream_config.record and stream_config.record_path:
                path_config["recordPath"] = stream_config.record_path
    
            # Add stream path via MediaMTX API
>           async with self._session.post(
                f"{self._base_url}/v3/config/paths/add/{stream_config.name}",
                json=path_config,
            ) as response:
E           AttributeError: __aenter__

src/mediamtx_wrapper/controller.py:407: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:47 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Creating stream path: recording_stream from /dev/video1
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:374 Creating stream path: recording_stream from /dev/video1
_____ TestHealthMonitorBackoffJitter.test_exponential_backoff_calculation ______

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_backoff_jitter.TestHealthMonitorBackoffJitter object at 0x7faac7472f80>
controller_backoff_test = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4a824d0>
mock_session = <Mock id='140371420517936'>

    @pytest.mark.asyncio
    async def test_exponential_backoff_calculation(
        self, controller_backoff_test, mock_session
    ):
        """Test exponential backoff interval calculation."""
        controller = controller_backoff_test
        controller._session = mock_session
    
        failure_response = self._mock_response(500, text_data="Service Error")
    
        # All failures to trigger exponential backoff
        responses = [failure_response] * 10
        mock_session.get.side_effect = responses
    
        # Mock asyncio.sleep to capture sleep intervals
        sleep_intervals = []
    
        async def mock_sleep(interval):
            sleep_intervals.append(interval)
            await asyncio.sleep(0.01)  # Short actual sleep for test speed
    
        with patch("asyncio.sleep", side_effect=mock_sleep):
            await controller.start()
>           await asyncio.sleep(0.3)  # Let several failures occur

tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:75: in mock_sleep
    await asyncio.sleep(0.01)  # Short actual sleep for test speed
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:75: in mock_sleep
    await asyncio.sleep(0.01)  # Short actual sleep for test speed
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
E   RecursionError: maximum recursion depth exceeded
!!! Recursion detected (same locals & position)
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [1639c06e] Starting MediaMTX controller
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [1639c06e] MediaMTX controller started successfully
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [48fc3042] Starting MediaMTX health monitoring loop
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
--------------------------- Captured stdout teardown ---------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [16fadb13] Health monitoring loop cancelled
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [16fadb13] Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
---------------------------- Captured log teardown -----------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
___________ TestHealthMonitorBackoffJitter.test_backoff_with_jitter ____________

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_backoff_jitter.TestHealthMonitorBackoffJitter object at 0x7faac74726b0>
mock_session = <Mock id='140371449090768'>

    @pytest.mark.asyncio
    async def test_backoff_with_jitter(self, mock_session):
        """Test backoff calculation with jitter applied."""
        controller = MediaMTXController(
            host="localhost",
            api_port=9997,
            rtsp_port=8554,
            webrtc_port=8889,
            hls_port=8888,
            config_path="/tmp/config.yml",
            recordings_path="/tmp/recordings",
            snapshots_path="/tmp/snapshots",
            health_check_interval=0.1,
            health_failure_threshold=5,
            health_max_backoff_interval=2.0,
            backoff_base_multiplier=2.0,
            backoff_jitter_range=(0.8, 1.2),  # ±20% jitter
            health_circuit_breaker_timeout=10.0,
        )
        controller._session = mock_session
    
        failure_response = self._mock_response(500, text_data="Error")
        responses = [failure_response] * 8
        mock_session.get.side_effect = responses
    
        sleep_intervals = []
    
        async def mock_sleep(interval):
            sleep_intervals.append(interval)
            await asyncio.sleep(0.01)
    
        with patch("asyncio.sleep", side_effect=mock_sleep):
            await controller.start()
>           await asyncio.sleep(0.25)

tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:128: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:128: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
E   RecursionError: maximum recursion depth exceeded
!!! Recursion detected (same locals & position)
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [16fadb13] Starting MediaMTX controller
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [16fadb13] MediaMTX controller started successfully
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [20325568] Starting MediaMTX health monitoring loop
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
--------------------------- Captured stdout teardown ---------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [8cc8d93c] Health monitoring loop cancelled
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [8cc8d93c] Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
---------------------------- Captured log teardown -----------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
_____ TestHealthMonitorBackoffJitter.test_backoff_maximum_cap_enforcement ______

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_backoff_jitter.TestHealthMonitorBackoffJitter object at 0x7faac7472ce0>
controller_backoff_test = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac46c8850>
mock_session = <Mock id='140371416614896'>

    @pytest.mark.asyncio
    async def test_backoff_maximum_cap_enforcement(
        self, controller_backoff_test, mock_session
    ):
        """Test that backoff intervals are capped at maximum value."""
        controller = controller_backoff_test
        controller._session = mock_session
        controller._health_max_backoff_interval = 1.0  # Lower cap for testing
    
        failure_response = self._mock_response(500, text_data="Error")
        responses = [failure_response] * 15  # Many failures to exceed cap
        mock_session.get.side_effect = responses
    
        sleep_intervals = []
    
        async def mock_sleep(interval):
            sleep_intervals.append(interval)
            await asyncio.sleep(0.01)
    
        with patch("asyncio.sleep", side_effect=mock_sleep):
            await controller.start()
>           await asyncio.sleep(0.4)

tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:163: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:163: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
E   RecursionError: maximum recursion depth exceeded
!!! Recursion detected (same locals & position)
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [8cc8d93c] Starting MediaMTX controller
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [8cc8d93c] MediaMTX controller started successfully
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [a5bf6749] Starting MediaMTX health monitoring loop
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
--------------------------- Captured stdout teardown ---------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [84d331b4] Health monitoring loop cancelled
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [84d331b4] Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
---------------------------- Captured log teardown -----------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
_________ TestHealthMonitorBackoffJitter.test_backoff_reset_on_success _________

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_backoff_jitter.TestHealthMonitorBackoffJitter object at 0x7faac7472890>
controller_backoff_test = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac48aab90>
mock_session = <Mock id='140371418590000'>

    @pytest.mark.asyncio
    async def test_backoff_reset_on_success(
        self, controller_backoff_test, mock_session
    ):
        """Test that backoff resets when health check succeeds."""
        controller = controller_backoff_test
        controller._session = mock_session
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures (build up backoff) → success (reset) → failures again
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Build backoff
            success_response,  # Reset backoff
            failure_response,
            failure_response,  # Fresh backoff sequence
        ]
        mock_session.get.side_effect = responses
    
        sleep_intervals = []
    
        async def mock_sleep(interval):
            sleep_intervals.append(interval)
            await asyncio.sleep(0.01)
    
        with patch("asyncio.sleep", side_effect=mock_sleep):
            await controller.start()
>           await asyncio.sleep(0.4)

tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:206: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:206: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
E   RecursionError: maximum recursion depth exceeded
!!! Recursion detected (same locals & position)
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [84d331b4] Starting MediaMTX controller
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [84d331b4] MediaMTX controller started successfully
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [de2b4457] Starting MediaMTX health monitoring loop
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
--------------------------- Captured stdout teardown ---------------------------
2025-08-10 12:09:48 - asyncio - ERROR - [36d19220] Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x7faac6604c40>
2025-08-10 12:09:48 - asyncio - ERROR - [36d19220] Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x7faac4bb95a0>
2025-08-10 12:09:48 - asyncio - ERROR - [36d19220] Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x7faac470f580>
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [36d19220] Health monitoring loop cancelled
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [36d19220] Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
---------------------------- Captured log teardown -----------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
___ TestHealthMonitorBackoffJitter.test_circuit_breaker_backoff_interaction ____

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_backoff_jitter.TestHealthMonitorBackoffJitter object at 0x7faac74701c0>
controller_backoff_test = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac444e380>
mock_session = <Mock id='140371414014640'>

    @pytest.mark.asyncio
    async def test_circuit_breaker_backoff_interaction(
        self, controller_backoff_test, mock_session
    ):
        """Test backoff behavior when circuit breaker is active."""
        controller = controller_backoff_test
        controller._session = mock_session
        controller._health_failure_threshold = 2  # Low threshold to trigger CB quickly
    
        failure_response = self._mock_response(500, text_data="Error")
        responses = [failure_response] * 8  # Enough to trigger CB and continue
        mock_session.get.side_effect = responses
    
        sleep_intervals = []
    
        async def mock_sleep(interval):
            sleep_intervals.append(interval)
            await asyncio.sleep(0.01)
    
        with patch("asyncio.sleep", side_effect=mock_sleep):
            await controller.start()
>           await asyncio.sleep(0.3)

tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:320: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:316: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:316: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
E   RecursionError: maximum recursion depth exceeded
!!! Recursion detected (same locals & position)
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [36d19220] Starting MediaMTX controller
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [36d19220] MediaMTX controller started successfully
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [a0bcd241] Starting MediaMTX health monitoring loop
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
--------------------------- Captured stdout teardown ---------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [91e0c901] Health monitoring loop cancelled
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [91e0c901] Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
---------------------------- Captured log teardown -----------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
___ TestHealthMonitorBackoffJitter.test_deterministic_backoff_with_no_jitter ___

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_backoff_jitter.TestHealthMonitorBackoffJitter object at 0x7faac7473370>
controller_backoff_test = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac47acdf0>
mock_session = <Mock id='140371417550272'>

    @pytest.mark.asyncio
    async def test_deterministic_backoff_with_no_jitter(
        self, controller_backoff_test, mock_session
    ):
        """Test that backoff is deterministic when jitter is disabled."""
        controller = controller_backoff_test
        controller._session = mock_session
        controller._backoff_jitter_range = (1.0, 1.0)  # No jitter
    
        failure_response = self._mock_response(500, text_data="Error")
        responses = [failure_response] * 6
        mock_session.get.side_effect = responses
    
        sleep_intervals = []
    
        async def mock_sleep(interval):
            sleep_intervals.append(interval)
            await asyncio.sleep(0.01)
    
        with patch("asyncio.sleep", side_effect=mock_sleep):
            await controller.start()
>           await asyncio.sleep(0.25)

tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:356: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:352: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py:352: in mock_sleep
    await asyncio.sleep(0.01)
/usr/lib/python3.10/unittest/mock.py:2245: in _execute_mock_call
    result = await effect(*args, **kwargs)
E   RecursionError: maximum recursion depth exceeded
!!! Recursion detected (same locals & position)
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [91e0c901] Starting MediaMTX controller
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [91e0c901] MediaMTX controller started successfully
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [b5d73c1d] Starting MediaMTX health monitoring loop
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
--------------------------- Captured stdout teardown ---------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [d515471a] Health monitoring loop cancelled
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [d515471a] Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
---------------------------- Captured log teardown -----------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=0, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
_____ TestHealthMonitorFlapping.test_circuit_breaker_activation_threshold ______

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_circuit_breaker_flapping.TestHealthMonitorFlapping object at 0x7faac74d8280>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4bd4490>
mock_session = <Mock id='140371421905968'>

    @pytest.mark.asyncio
    async def test_circuit_breaker_activation_threshold(
        self, controller_fast_timers, mock_session
    ):
        """Test circuit breaker opens exactly at configured failure threshold."""
        controller = controller_fast_timers
        controller._session = mock_session
    
        failure_response = self._mock_response(500, text_data="Service Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: 2 failures (below threshold) → 1 success → 3 failures (trigger CB)
        responses = [
            failure_response,
            failure_response,  # 2 failures - should not trigger CB
            success_response,  # Reset consecutive failures
            failure_response,
            failure_response,
            failure_response,  # 3 failures - should trigger CB
        ]
        mock_session.get.side_effect = responses
    
        await controller.start()
        await asyncio.sleep(0.4)  # Let sequence run
        await controller.stop()
    
        # Verify circuit breaker activated exactly once
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py:84: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [d515471a] Starting MediaMTX controller
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [d515471a] MediaMTX controller started successfully
2025-08-10 12:09:48 - src.mediamtx_wrapper.controller - INFO - [6cabda2c] Starting MediaMTX health monitoring loop
2025-08-10 12:09:48 - asyncio - ERROR - [1141c44d] Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x7faac451d450>
2025-08-10 12:09:48 - asyncio - ERROR - [1141c44d] Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x7faac4bcc130>
2025-08-10 12:09:48 - asyncio - ERROR - [1141c44d] Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x7faac4743ac0>
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f7e226d9] Stopping MediaMTX controller
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f7e226d9] Health monitoring loop cancelled
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f7e226d9] Health monitoring loop ended - Final stats: checks=7, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f7e226d9] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
ERROR    asyncio:base_events.py:1758 Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x7faac451d450>
ERROR    asyncio:base_events.py:1758 Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x7faac4bcc130>
ERROR    asyncio:base_events.py:1758 Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x7faac4743ac0>
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=7, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
______ TestHealthMonitorFlapping.test_flapping_resistance_during_recovery ______

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_circuit_breaker_flapping.TestHealthMonitorFlapping object at 0x7faac74da8f0>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4740fd0>
mock_session = <Mock id='140371417109296'>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7faac47ac730>

    @pytest.mark.asyncio
    async def test_flapping_resistance_during_recovery(
        self, controller_fast_timers, mock_session, caplog
    ):
        """Test circuit breaker resists flapping during recovery phase."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 3
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB → timeout → alternating success/failure (should not
        # fully recover)
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            success_response,  # 1st success during recovery
            failure_response,  # Reset confirmation counter
            success_response,  # 1st success again
            failure_response,  # Reset confirmation counter again
            success_response,  # 1st success yet again
            success_response,  # 2nd consecutive success
            success_response,  # 3rd consecutive success - should fully recover
        ]
        mock_session.get.side_effect = responses
    
        with caplog.at_level("INFO"):
            await controller.start()
            await asyncio.sleep(0.6)  # Let recovery sequence run
            await controller.stop()
    
        # Verify circuit breaker eventually recovered after stable successes
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py:121: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f7e226d9] Starting MediaMTX controller
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f7e226d9] MediaMTX controller started successfully
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f8456bd6] Starting MediaMTX health monitoring loop
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f242ba51] Stopping MediaMTX controller
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f242ba51] Health monitoring loop cancelled
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f242ba51] Health monitoring loop ended - Final stats: checks=12, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f242ba51] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=12, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
____________ TestHealthMonitorFlapping.test_rapid_flapping_scenario ____________

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_circuit_breaker_flapping.TestHealthMonitorFlapping object at 0x7faac74d9990>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4a80460>
mock_session = <Mock id='140371420519664'>

    @pytest.mark.asyncio
    async def test_rapid_flapping_scenario(self, controller_fast_timers, mock_session):
        """Test circuit breaker behavior under rapid success/failure alternation."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 2
    
        failure_response = self._mock_response(503, text_data="Unavailable")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB → rapid alternation → eventual stable recovery
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            # Rapid alternation during recovery (10 cycles)
            success_response,
            failure_response,  # Reset
            success_response,
            failure_response,  # Reset
            success_response,
            failure_response,  # Reset
            success_response,
            failure_response,  # Reset
            success_response,
            failure_response,  # Reset
            # Finally stable recovery
            success_response,
            success_response,  # Should fully recover
        ]
        mock_session.get.side_effect = responses
    
        await controller.start()
        await asyncio.sleep(0.8)  # Extended time for rapid sequence
        await controller.stop()
    
        # Verify circuit breaker stayed stable during flapping
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py:166: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f242ba51] Starting MediaMTX controller
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [f242ba51] MediaMTX controller started successfully
2025-08-10 12:09:49 - src.mediamtx_wrapper.controller - INFO - [58076e10] Starting MediaMTX health monitoring loop
2025-08-10 12:09:50 - src.mediamtx_wrapper.controller - INFO - [25e6ff9d] Stopping MediaMTX controller
2025-08-10 12:09:50 - src.mediamtx_wrapper.controller - INFO - [25e6ff9d] Health monitoring loop cancelled
2025-08-10 12:09:50 - src.mediamtx_wrapper.controller - INFO - [25e6ff9d] Health monitoring loop ended - Final stats: checks=16, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=2
2025-08-10 12:09:50 - src.mediamtx_wrapper.controller - INFO - [25e6ff9d] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=16, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=2
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
________ TestHealthMonitorFlapping.test_multiple_circuit_breaker_cycles ________

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_circuit_breaker_flapping.TestHealthMonitorFlapping object at 0x7faac74d9cc0>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4bb85e0>
mock_session = <Mock id='140371421801648'>

    @pytest.mark.asyncio
    async def test_multiple_circuit_breaker_cycles(
        self, controller_fast_timers, mock_session
    ):
        """Test multiple circuit breaker activation/recovery cycles."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 2
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: CB cycle 1 → recovery → CB cycle 2 → recovery
        responses = [
            # First CB cycle
            failure_response,
            failure_response,
            failure_response,  # Trigger CB #1
            success_response,
            success_response,  # Recover from CB #1
            # Second CB cycle
            failure_response,
            failure_response,
            failure_response,  # Trigger CB #2
            success_response,
            success_response,  # Recover from CB #2
        ]
        mock_session.get.side_effect = responses
    
        await controller.start()
        await asyncio.sleep(0.8)  # Extended time for two cycles
        await controller.stop()
    
        # Verify both circuit breaker cycles occurred
>       assert controller._health_state["circuit_breaker_activations"] == 2
E       assert 0 == 2

tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py:205: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:50 - src.mediamtx_wrapper.controller - INFO - [25e6ff9d] Starting MediaMTX controller
2025-08-10 12:09:50 - src.mediamtx_wrapper.controller - INFO - [25e6ff9d] MediaMTX controller started successfully
2025-08-10 12:09:50 - src.mediamtx_wrapper.controller - INFO - [e1f91186] Starting MediaMTX health monitoring loop
2025-08-10 12:09:51 - src.mediamtx_wrapper.controller - INFO - [72069935] Stopping MediaMTX controller
2025-08-10 12:09:51 - src.mediamtx_wrapper.controller - INFO - [72069935] Health monitoring loop cancelled
2025-08-10 12:09:51 - src.mediamtx_wrapper.controller - INFO - [72069935] Health monitoring loop ended - Final stats: checks=16, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=2
2025-08-10 12:09:51 - src.mediamtx_wrapper.controller - INFO - [72069935] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=16, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=2
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
___ TestHealthMonitorFlapping.test_recovery_confirmation_boundary_conditions ___

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_circuit_breaker_flapping.TestHealthMonitorFlapping object at 0x7faac74d9210>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4bdd930>
mock_session = <Mock id='140371421946224'>

    @pytest.mark.asyncio
    async def test_recovery_confirmation_boundary_conditions(
        self, controller_fast_timers, mock_session
    ):
        """Test recovery confirmation at exactly the threshold boundary."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 4  # Higher threshold
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB → exactly N-1 successes → failure → N successes
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            success_response,
            success_response,
            success_response,  # 3/4 successes (not enough)
            failure_response,  # Reset confirmation counter
            success_response,
            success_response,
            success_response,
            success_response,  # 4/4 successes (should recover)
        ]
        mock_session.get.side_effect = responses
    
        await controller.start()
        await asyncio.sleep(0.7)
        await controller.stop()
    
        # Verify recovery required exactly the configured threshold
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py:241: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:51 - src.mediamtx_wrapper.controller - INFO - [72069935] Starting MediaMTX controller
2025-08-10 12:09:51 - src.mediamtx_wrapper.controller - INFO - [72069935] MediaMTX controller started successfully
2025-08-10 12:09:51 - src.mediamtx_wrapper.controller - INFO - [2d98f0e5] Starting MediaMTX health monitoring loop
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [704441f8] Stopping MediaMTX controller
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [704441f8] Health monitoring loop cancelled
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [704441f8] Health monitoring loop ended - Final stats: checks=14, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=4
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [704441f8] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=14, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=4
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
______ TestHealthMonitorFlapping.test_no_premature_circuit_breaker_reset _______

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_circuit_breaker_flapping.TestHealthMonitorFlapping object at 0x7faac74da710>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac46cbf70>
mock_session = <Mock id='140371416627280'>

    @pytest.mark.asyncio
    async def test_no_premature_circuit_breaker_reset(
        self, controller_fast_timers, mock_session
    ):
        """Test that transient successes don't prematurely reset circuit breaker state."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 3
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB → single success → more failures (should not reset CB
        # state)
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            success_response,  # Single success (insufficient)
            failure_response,
            failure_response,  # More failures during recovery
        ]
        mock_session.get.side_effect = responses
    
        await controller.start()
        await asyncio.sleep(0.5)
        await controller.stop()
    
        # Verify circuit breaker activated but did not recover
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py:273: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [704441f8] Starting MediaMTX controller
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [704441f8] MediaMTX controller started successfully
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [13177d59] Starting MediaMTX health monitoring loop
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [be3c6161] Stopping MediaMTX controller
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [be3c6161] Health monitoring loop cancelled
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [be3c6161] Health monitoring loop ended - Final stats: checks=10, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [be3c6161] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=10, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
_ TestHealthMonitorRecoveryConfirmation.test_exact_consecutive_success_requirement _

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_recovery_confirmation.TestHealthMonitorRecoveryConfirmation object at 0x7faac746bc70>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4bcd4e0>
mock_session = <Mock id='140371421876080'>

    @pytest.mark.asyncio
    async def test_exact_consecutive_success_requirement(
        self, controller_fast_timers, mock_session
    ):
        """Test that recovery requires exactly the configured number of consecutive successes."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = (
            4  # Require 4 consecutive successes
        )
    
        failure_response = self._mock_response(500, text_data="Service Error")
        success_response = self._mock_response(
            200, {"serverVersion": "1.0.0", "serverUptime": 1200}
        )
    
        # Pattern: failures → CB timeout → exactly 4 consecutive successes
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            success_response,
            success_response,
            success_response,
            success_response,  # Exactly 4 successes
        ]
        mock_session.get.side_effect = responses
    
        await controller.start()
        await asyncio.sleep(0.5)  # Let recovery sequence complete
        await controller.stop()
    
        # Verify recovery occurred after exactly 4 consecutive successes
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py:91: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [be3c6161] Starting MediaMTX controller
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [be3c6161] MediaMTX controller started successfully
2025-08-10 12:09:52 - src.mediamtx_wrapper.controller - INFO - [4f6e7c8c] Starting MediaMTX health monitoring loop
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [06ba0739] Stopping MediaMTX controller
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [06ba0739] Health monitoring loop cancelled
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [06ba0739] Health monitoring loop ended - Final stats: checks=10, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=4
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [06ba0739] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=10, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=4
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
_ TestHealthMonitorRecoveryConfirmation.test_insufficient_consecutive_successes _

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_recovery_confirmation.TestHealthMonitorRecoveryConfirmation object at 0x7faac746beb0>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac660ea10>
mock_session = <Mock id='140371449409744'>

    @pytest.mark.asyncio
    async def test_insufficient_consecutive_successes(
        self, controller_fast_timers, mock_session
    ):
        """Test that N-1 consecutive successes do not trigger recovery."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 3
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB timeout → only 2 successes (insufficient for threshold
        # of 3)
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            success_response,
            success_response,  # Only 2/3 required successes
        ]
        mock_session.get.side_effect = responses
    
        await controller.start()
        await asyncio.sleep(0.4)
        await controller.stop()
    
        # Verify circuit breaker did not recover
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py:125: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [06ba0739] Starting MediaMTX controller
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [06ba0739] MediaMTX controller started successfully
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [fcaa513a] Starting MediaMTX health monitoring loop
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [bc9331b9] Stopping MediaMTX controller
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [bc9331b9] Health monitoring loop cancelled
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [bc9331b9] Health monitoring loop ended - Final stats: checks=8, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [bc9331b9] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=8, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
_ TestHealthMonitorRecoveryConfirmation.test_failure_resets_confirmation_progress _

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_recovery_confirmation.TestHealthMonitorRecoveryConfirmation object at 0x7faac746a5f0>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4b8bfd0>
mock_session = <Mock id='140371421609360'>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7faac475f9d0>

    @pytest.mark.asyncio
    async def test_failure_resets_confirmation_progress(
        self, controller_fast_timers, mock_session, caplog
    ):
        """Test that any failure during recovery resets the confirmation counter."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 3
    
        failure_response = self._mock_response(503, text_data="Service Unavailable")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB → 2 successes → failure (reset) → 3 successes (recover)
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            success_response,
            success_response,  # 2/3 successes
            failure_response,  # Reset confirmation progress
            success_response,
            success_response,
            success_response,  # 3 consecutive successes
        ]
        mock_session.get.side_effect = responses
    
        with caplog.at_level("INFO"):
            await controller.start()
            await asyncio.sleep(0.6)
            await controller.stop()
    
        # Verify eventual recovery after reset
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py:163: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [bc9331b9] Starting MediaMTX controller
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [bc9331b9] MediaMTX controller started successfully
2025-08-10 12:09:53 - src.mediamtx_wrapper.controller - INFO - [647cc967] Starting MediaMTX health monitoring loop
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [1db0b9da] Stopping MediaMTX controller
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [1db0b9da] Health monitoring loop cancelled
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [1db0b9da] Health monitoring loop ended - Final stats: checks=12, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [1db0b9da] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=12, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
_ TestHealthMonitorRecoveryConfirmation.test_circuit_breaker_timeout_behavior __

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_recovery_confirmation.TestHealthMonitorRecoveryConfirmation object at 0x7faac74683a0>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac482ff70>
mock_session = <Mock id='140371418086704'>

    @pytest.mark.asyncio
    async def test_circuit_breaker_timeout_behavior(
        self, controller_fast_timers, mock_session
    ):
        """Test circuit breaker timeout behavior before recovery attempts."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_circuit_breaker_timeout = 0.3  # Short timeout for testing
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB → wait for timeout → immediate recovery
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            success_response,
            success_response,
            success_response,  # Immediate recovery after timeout
        ]
        mock_session.get.side_effect = responses
    
        start_time = time.time()
        await controller.start()
        await asyncio.sleep(0.6)  # Wait for timeout + recovery
        await controller.stop()
        elapsed = time.time() - start_time
    
        # Verify circuit breaker timeout was respected
        assert elapsed >= 0.3, "Should respect circuit breaker timeout"
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py:206: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [1db0b9da] Starting MediaMTX controller
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [1db0b9da] MediaMTX controller started successfully
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [c1f6ed68] Starting MediaMTX health monitoring loop
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [e4258e4d] Stopping MediaMTX controller
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [e4258e4d] Health monitoring loop cancelled
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [e4258e4d] Health monitoring loop ended - Final stats: checks=12, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [e4258e4d] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=12, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=3
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
______ TestHealthMonitorRecoveryConfirmation.test_recovery_state_tracking ______

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_recovery_confirmation.TestHealthMonitorRecoveryConfirmation object at 0x7faac74686d0>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4acf220>
mock_session = <Mock id='140371420828608'>

    @pytest.mark.asyncio
    async def test_recovery_state_tracking(self, controller_fast_timers, mock_session):
        """Test internal state tracking during recovery process."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 2
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB → track progress through recovery
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            success_response,  # 1/2 successes
            success_response,  # 2/2 successes (full recovery)
        ]
        mock_session.get.side_effect = responses
    
        await controller.start()
        await asyncio.sleep(0.4)
    
        # Check intermediate state before full recovery
        # Note: We can't easily check intermediate state during execution,
        # so we verify final state after completion
        await controller.stop()
    
        # Verify state was properly tracked and reset
>       assert controller._health_state["circuit_breaker_activations"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py:238: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [e4258e4d] Starting MediaMTX controller
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [e4258e4d] MediaMTX controller started successfully
2025-08-10 12:09:54 - src.mediamtx_wrapper.controller - INFO - [07fc2d2c] Starting MediaMTX health monitoring loop
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [a56c4a1b] Stopping MediaMTX controller
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [a56c4a1b] Health monitoring loop cancelled
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [a56c4a1b] Health monitoring loop ended - Final stats: checks=7, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=2
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [a56c4a1b] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=7, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=2
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
_ TestHealthMonitorRecoveryConfirmation.test_configurable_confirmation_threshold _

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_recovery_confirmation.TestHealthMonitorRecoveryConfirmation object at 0x7faac74683d0>
mock_session = <Mock id='140371418590384'>

    @pytest.mark.asyncio
    async def test_configurable_confirmation_threshold(self, mock_session):
        """Test different confirmation threshold configurations."""
        # Test with threshold = 1 (immediate recovery)
        controller_fast = MediaMTXController(
            host="localhost",
            api_port=9997,
            rtsp_port=8554,
            webrtc_port=8889,
            hls_port=8888,
            config_path="/tmp/config.yml",
            recordings_path="/tmp/recordings",
            snapshots_path="/tmp/snapshots",
            health_check_interval=0.05,
            health_failure_threshold=2,
            health_circuit_breaker_timeout=0.1,
            health_recovery_confirmation_threshold=1,
        )
        controller_fast._session = mock_session
    
        # Test with threshold = 5 (slow recovery)
        controller_slow = MediaMTXController(
            host="localhost",
            api_port=9997,
            rtsp_port=8554,
            webrtc_port=8889,
            hls_port=8888,
            config_path="/tmp/config.yml",
            recordings_path="/tmp/recordings",
            snapshots_path="/tmp/snapshots",
            health_check_interval=0.05,
            health_failure_threshold=2,
            health_circuit_breaker_timeout=0.1,
            health_recovery_confirmation_threshold=5,
        )
        controller_slow._session = mock_session
    
        # Verify configuration is applied
        assert controller_fast._health_recovery_confirmation_threshold == 1
        assert controller_slow._health_recovery_confirmation_threshold == 5
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Test fast recovery (1 success)
        mock_session.get.side_effect = [
            failure_response,
            failure_response,
            success_response,
        ]
        await controller_fast.start()
        await asyncio.sleep(0.3)
        await controller_fast.stop()
    
        # Fast controller should recover immediately
>       assert controller_fast._health_state["recovery_count"] == 1
E       assert 0 == 1

tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py:299: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [a56c4a1b] Starting MediaMTX controller
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [a56c4a1b] MediaMTX controller started successfully
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [a8bae86c] Starting MediaMTX health monitoring loop
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [9a313ace] Stopping MediaMTX controller
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [9a313ace] Health monitoring loop cancelled
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [9a313ace] Health monitoring loop ended - Final stats: checks=6, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=1
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [9a313ace] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=6, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=1
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
_____ TestHealthMonitorRecoveryConfirmation.test_partial_recovery_logging ______

self = <tests.unit.test_mediamtx_wrapper.test_health_monitor_recovery_confirmation.TestHealthMonitorRecoveryConfirmation object at 0x7faac7469a80>
controller_fast_timers = <src.mediamtx_wrapper.controller.MediaMTXController object at 0x7faac4d24ee0>
mock_session = <Mock id='140371423288704'>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7faac47afee0>

    @pytest.mark.asyncio
    async def test_partial_recovery_logging(
        self, controller_fast_timers, mock_session, caplog
    ):
        """Test that partial recovery progress is properly logged."""
        controller = controller_fast_timers
        controller._session = mock_session
        controller._health_recovery_confirmation_threshold = 4
    
        failure_response = self._mock_response(500, text_data="Error")
        success_response = self._mock_response(200, {"serverVersion": "1.0.0"})
    
        # Pattern: failures → CB → partial recovery → reset → full recovery
        responses = [
            failure_response,
            failure_response,
            failure_response,  # Trigger CB
            success_response,
            success_response,  # 2/4 successes (partial)
            failure_response,  # Reset
            success_response,
            success_response,
            success_response,
            success_response,  # Full recovery
        ]
        mock_session.get.side_effect = responses
    
        with caplog.at_level("INFO"):
            await controller.start()
            await asyncio.sleep(0.7)
            await controller.stop()
    
        # Verify different recovery states were logged
        log_messages = [record.message for record in caplog.records]
        improving_logs = [msg for msg in log_messages if "IMPROVING" in msg]
        recovered_logs = [msg for msg in log_messages if "FULLY RECOVERED" in msg]
        degraded_logs = [msg for msg in log_messages if "DEGRADED" in msg]
    
>       assert len(improving_logs) >= 1, "Should log partial recovery progress"
E       AssertionError: Should log partial recovery progress
E       assert 0 >= 1
E        +  where 0 = len([])

tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py:355: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [9a313ace] Starting MediaMTX controller
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [9a313ace] MediaMTX controller started successfully
2025-08-10 12:09:55 - src.mediamtx_wrapper.controller - INFO - [afe48d01] Starting MediaMTX health monitoring loop
2025-08-10 12:09:56 - src.mediamtx_wrapper.controller - INFO - [eedc635e] Stopping MediaMTX controller
2025-08-10 12:09:56 - src.mediamtx_wrapper.controller - INFO - [eedc635e] Health monitoring loop cancelled
2025-08-10 12:09:56 - src.mediamtx_wrapper.controller - INFO - [eedc635e] Health monitoring loop ended - Final stats: checks=14, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=4
2025-08-10 12:09:56 - src.mediamtx_wrapper.controller - INFO - [eedc635e] MediaMTX controller stopped
------------------------------ Captured log call -------------------------------
INFO     src.mediamtx_wrapper.controller:controller.py:161 Starting MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:182 MediaMTX controller started successfully
INFO     src.mediamtx_wrapper.controller:controller.py:1354 Starting MediaMTX health monitoring loop
INFO     src.mediamtx_wrapper.controller:controller.py:206 Stopping MediaMTX controller
INFO     src.mediamtx_wrapper.controller:controller.py:1531 Health monitoring loop cancelled
INFO     src.mediamtx_wrapper.controller:controller.py:1585 Health monitoring loop ended - Final stats: checks=14, recoveries=0, failures=0, circuit_breaker_activations=0, recovery_confirmation_threshold=4
INFO     src.mediamtx_wrapper.controller:controller.py:224 MediaMTX controller stopped
________ TestServerMethodHandlers.test_take_snapshot_parameter_handling ________

self = <tests.unit.test_websocket_server.test_server_method_handlers.TestServerMethodHandlers object at 0x7faac654d510>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4d242b0>

    @pytest.mark.asyncio
    async def test_take_snapshot_parameter_handling(self, server):
        """Test snapshot method parameter processing."""
        # Mock MediaMTX controller
        mock_controller = Mock()
        mock_controller.take_snapshot = AsyncMock(
            return_value={
                "filename": "test_snapshot.jpg",
                "file_size": 12345,
                "file_path": "/opt/snapshots/test_snapshot.jpg",
            }
        )
        server._mediamtx_controller = mock_controller
    
        # Test with device parameter only
>       result = await server._method_take_snapshot({"device": "/dev/video0"})

tests/unit/test_websocket_server/test_server_method_handlers.py:103: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4d242b0>
params = {'device': '/dev/video0'}

    async def _method_take_snapshot(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Take a snapshot from the specified camera.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
                - format (str, optional): Snapshot format (jpg, png)
                - quality (int, optional): Image quality (1-100)
    
        Returns:
            Dict containing snapshot information
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
        # Parameter validation and normalization
        format_type = params.get("format", "jpg")
        quality = params.get("quality", 85)
        if not isinstance(quality, int) or not (1 <= quality <= 100):
            raise ValueError("Invalid params")
        if format_type not in ("jpg", "png"):
            format_type = "jpg"
        custom_filename = params.get("filename")
    
        # Get MediaMTX controller from service manager if available
        mediamtx_controller = None
>       if self._service_manager and hasattr(self._service_manager, '_mediamtx_controller'):
E       AttributeError: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'. Did you mean: 'set_service_manager'?

src/websocket_server/server.py:1345: AttributeError
______ TestServerMethodHandlers.test_recording_methods_parameter_handling ______

self = <tests.unit.test_websocket_server.test_server_method_handlers.TestServerMethodHandlers object at 0x7faac654d270>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4a82c80>

    @pytest.mark.asyncio
    async def test_recording_methods_parameter_handling(self, server):
        """Test recording method parameter processing."""
        # Mock MediaMTX controller
        mock_controller = Mock()
        mock_controller.start_recording = AsyncMock(
            return_value={
                "filename": "test_recording.mp4",
                "start_time": "2025-08-03T12:00:00Z",
            }
        )
        mock_controller.stop_recording = AsyncMock(
            return_value={
                "filename": "test_recording.mp4",
                "start_time": "2025-08-03T12:00:00Z",
                "duration": 3600,
                "file_size": 1073741824,
            }
        )
        server._mediamtx_controller = mock_controller
    
        # Test start_recording with parameters
>       result = await server._method_start_recording(
            {"device": "/dev/video0", "duration": 3600, "format": "mp4"}
        )

tests/unit/test_websocket_server/test_server_method_handlers.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4a82c80>
params = {'device': '/dev/video0', 'duration': 3600, 'format': 'mp4'}

    async def _method_start_recording(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Start recording video from the specified camera.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
                - duration (int, optional): Recording duration in seconds
                - format (str, optional): Recording format
    
        Returns:
            Dict containing recording session information
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
        # Parameter normalization and validation
        duration = params.get("duration")
        duration_seconds = params.get("duration_seconds")
        duration_minutes = params.get("duration_minutes")
        duration_hours = params.get("duration_hours")
        format_type = params.get("format", "mp4")
    
        # Normalize format (only mp4 supported at this stage)
        if format_type not in ("mp4",):
            format_type = "mp4"
    
        # Determine effective duration (seconds)
        effective_duration = None
        if duration is not None:
            # legacy seconds param
            if not isinstance(duration, int) or duration < 1:
                raise ValueError("Invalid params")
            effective_duration = duration
        elif duration_seconds is not None:
            if not isinstance(duration_seconds, int) or not (1 <= duration_seconds <= 3600):
                raise ValueError("Invalid params")
            effective_duration = duration_seconds
        elif duration_minutes is not None:
            if not isinstance(duration_minutes, int) or not (1 <= duration_minutes <= 1440):
                raise ValueError("Invalid params")
            effective_duration = duration_minutes * 60
        elif duration_hours is not None:
            if not isinstance(duration_hours, int) or not (1 <= duration_hours <= 24):
                raise ValueError("Invalid params")
            effective_duration = duration_hours * 3600
        else:
            # Unlimited mode when no duration provided
            effective_duration = None
    
        # Get MediaMTX controller from service manager if available
        mediamtx_controller = None
>       if self._service_manager and hasattr(self._service_manager, '_mediamtx_controller'):
E       AttributeError: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'. Did you mean: 'set_service_manager'?

src/websocket_server/server.py:1442: AttributeError
_______ TestServerMethodHandlers.test_method_error_handling_no_mediamtx ________

self = <tests.unit.test_websocket_server.test_server_method_handlers.TestServerMethodHandlers object at 0x7faac654d720>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4bde3b0>

    @pytest.mark.asyncio
    async def test_method_error_handling_no_mediamtx(self, server):
        """Test method error handling when MediaMTX controller unavailable."""
        # Ensure no MediaMTX controller
        server._mediamtx_controller = None
    
        # Test snapshot without MediaMTX
>       result = await server._method_take_snapshot({"device": "/dev/video0"})

tests/unit/test_websocket_server/test_server_method_handlers.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4bde3b0>
params = {'device': '/dev/video0'}

    async def _method_take_snapshot(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Take a snapshot from the specified camera.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
                - format (str, optional): Snapshot format (jpg, png)
                - quality (int, optional): Image quality (1-100)
    
        Returns:
            Dict containing snapshot information
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
        # Parameter validation and normalization
        format_type = params.get("format", "jpg")
        quality = params.get("quality", 85)
        if not isinstance(quality, int) or not (1 <= quality <= 100):
            raise ValueError("Invalid params")
        if format_type not in ("jpg", "png"):
            format_type = "jpg"
        custom_filename = params.get("filename")
    
        # Get MediaMTX controller from service manager if available
        mediamtx_controller = None
>       if self._service_manager and hasattr(self._service_manager, '_mediamtx_controller'):
E       AttributeError: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'. Did you mean: 'set_service_manager'?

src/websocket_server/server.py:1345: AttributeError
_____________ TestServerMethodHandlers.test_stream_name_extraction _____________

self = <tests.unit.test_websocket_server.test_server_method_handlers.TestServerMethodHandlers object at 0x7faac654db10>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4acc280>

    def test_stream_name_extraction(self, server):
        """Test stream name extraction from device paths."""
        # Test standard video device paths
        assert server._get_stream_name_from_device_path("/dev/video0") == "camera0"
        assert server._get_stream_name_from_device_path("/dev/video15") == "camera15"
    
        # Test non-standard device paths
        stream_name = server._get_stream_name_from_device_path("/custom/device")
        assert stream_name.startswith("camera_")
        assert stream_name != "camera_unknown"  # Should generate deterministic hash
    
        # Test empty/invalid paths
>       assert server._get_stream_name_from_device_path("") == "camera_unknown"
E       AssertionError: assert 'camera_0' == 'camera_unknown'
E         
E         - camera_unknown
E         + camera_0

tests/unit/test_websocket_server/test_server_method_handlers.py:200: AssertionError
___________ TestServerMethodHandlers.test_method_exception_handling ____________

self = <tests.unit.test_websocket_server.test_server_method_handlers.TestServerMethodHandlers object at 0x7faac654df30>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac47b12a0>

    @pytest.mark.asyncio
    async def test_method_exception_handling(self, server):
        """Test exception handling in method execution."""
        # Mock MediaMTX controller that raises exceptions
        mock_controller = Mock()
        mock_controller.take_snapshot = AsyncMock(
            side_effect=Exception("MediaMTX error")
        )
        server._mediamtx_controller = mock_controller
    
        # Test that exceptions are caught and return error responses
>       result = await server._method_take_snapshot({"device": "/dev/video0"})

tests/unit/test_websocket_server/test_server_method_handlers.py:213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac47b12a0>
params = {'device': '/dev/video0'}

    async def _method_take_snapshot(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Take a snapshot from the specified camera.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
                - format (str, optional): Snapshot format (jpg, png)
                - quality (int, optional): Image quality (1-100)
    
        Returns:
            Dict containing snapshot information
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
        # Parameter validation and normalization
        format_type = params.get("format", "jpg")
        quality = params.get("quality", 85)
        if not isinstance(quality, int) or not (1 <= quality <= 100):
            raise ValueError("Invalid params")
        if format_type not in ("jpg", "png"):
            format_type = "jpg"
        custom_filename = params.get("filename")
    
        # Get MediaMTX controller from service manager if available
        mediamtx_controller = None
>       if self._service_manager and hasattr(self._service_manager, '_mediamtx_controller'):
E       AttributeError: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'. Did you mean: 'set_service_manager'?

src/websocket_server/server.py:1345: AttributeError
_____ TestServerMethodHandlers.test_method_handlers_with_mock_dependencies _____

self = <tests.unit.test_websocket_server.test_server_method_handlers.TestServerMethodHandlers object at 0x7faac654e500>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac48abb20>

    @pytest.mark.asyncio
    async def test_method_handlers_with_mock_dependencies(self, server):
        """Test method handlers with properly mocked dependencies."""
        # Setup mock camera monitor
        mock_camera_monitor = Mock()
        mock_camera_monitor.get_connected_cameras = AsyncMock(return_value={})
        server._camera_monitor = mock_camera_monitor
    
        # Setup mock MediaMTX controller
        mock_mediamtx = Mock()
        mock_mediamtx.get_stream_status = AsyncMock(return_value={"status": "inactive"})
        server._mediamtx_controller = mock_mediamtx
    
        # Test get_camera_list with mocked dependencies
>       result = await server._method_get_camera_list()

tests/unit/test_websocket_server/test_server_method_handlers.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac48abb20>
params = None

    async def _method_get_camera_list(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Get list of all discovered cameras with their current status and aggregated metadata.
    
        Integrates real data from camera discovery monitor (with provisional/confirmed capability logic)
        and MediaMTX controller. Returns architecture-compliant response structure.
    
        Args:
            params: Method parameters (unused)
    
        Returns:
            Object with camera list and metadata per API specification
        """
        # Get camera monitor from service manager if available
        camera_monitor = None
>       if self._service_manager and hasattr(self._service_manager, '_camera_monitor'):
E       AttributeError: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'. Did you mean: 'set_service_manager'?

src/websocket_server/server.py:1065: AttributeError
______ TestServerNotifications.test_send_notification_to_specific_client _______

self = <tests.unit.test_websocket_server.test_server_notifications.TestServerNotifications object at 0x7faac654d3c0>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac654dbd0>
mock_client = <src.websocket_server.server.ClientConnection object at 0x7faac475d3c0>

    @pytest.mark.asyncio
    async def test_send_notification_to_specific_client(self, server, mock_client):
        """Test sending notification to specific client."""
        # Add mock client to server
        server._clients["test-client-123"] = mock_client
    
        # Send notification to specific client
        result = await server.send_notification_to_client(
            client_id="test-client-123",
            method="camera_connected",
            params={"device": "/dev/video0", "status": "CONNECTED"},
        )
    
        # Verify notification was sent successfully
>       assert result is True
E       assert False is True

tests/unit/test_websocket_server/test_server_notifications.py:210: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:57 - src.websocket_server.server - INFO - [93be4cd9] Removed disconnected client during notification: test-client-123
------------------------------ Captured log call -------------------------------
INFO     src.websocket_server.server:server.py:871 Removed disconnected client during notification: test-client-123
_ TestServerStatusAggregation.test_get_camera_status_uses_real_capability_data _

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac482e0e0>
params = {'device': '/dev/video0'}

    async def _method_get_camera_status(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Get detailed status for a specific camera device with aggregated real data.
    
        Combines data from camera discovery monitor (with provisional/confirmed capability logic),
        MediaMTX controller (stream status and metrics), and provides graceful fallbacks.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
    
        Returns:
            Dict containing comprehensive camera status per API specification:
                - device, status, name, resolution, fps, streams, metrics, capabilities
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
    
        # Initialize response with architecture defaults
        camera_status = {
            "device": device_path,
            "status": "DISCONNECTED",
            "name": f"Camera {device_path.split('video')[-1] if 'video' in device_path else 'unknown'}",
            "resolution": "1920x1080",  # Architecture default
            "fps": 30,  # Architecture default
            "streams": {},
            "metrics": {"bytes_sent": 0, "readers": 0, "uptime": 0},
            "capabilities": {"formats": [], "resolutions": []},
        }
    
        try:
            # Get camera monitor from service manager if available
            camera_monitor = None
>           if self._service_manager and hasattr(self._service_manager, '_camera_monitor'):
E           AttributeError: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'. Did you mean: 'set_service_manager'?

src/websocket_server/server.py:1203: AttributeError

The above exception was the direct cause of the following exception:

self = <tests.unit.test_websocket_server.test_server_status_aggregation.TestServerStatusAggregation object at 0x7faac654fdc0>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac482e0e0>
mock_camera_monitor = <Mock id='140371414872128'>
mock_mediamtx_controller = <Mock id='140371418074560'>

    @pytest.mark.asyncio
    async def test_get_camera_status_uses_real_capability_data(
        self, server, mock_camera_monitor, mock_mediamtx_controller
    ):
        """Verify get_camera_status integrates real capability metadata when available."""
        # Setup connected cameras with real capability data
        mock_camera_device = CameraDevice(
            device="/dev/video0", name="Test Camera 0", status="CONNECTED"
        )
    
        mock_camera_monitor.get_connected_cameras.return_value = {
            "/dev/video0": mock_camera_device
        }
    
        # Mock capability metadata with provisional/confirmed data
        mock_capability_metadata = {
            "resolution": "1280x720",
            "fps": 25,
            "validation_status": "confirmed",
            "formats": ["YUYV", "MJPEG"],
            "all_resolutions": ["1920x1080", "1280x720", "640x480"],
            "consecutive_successes": 3,
        }
        mock_camera_monitor.get_effective_capability_metadata.return_value = (
            mock_capability_metadata
        )
    
        # Mock MediaMTX stream status
        mock_mediamtx_controller.get_stream_status.return_value = {
            "status": "active",
            "bytes_sent": 12345,
            "readers": 2,
        }
    
        # Test get_camera_status method
>       result = await server._method_get_camera_status({"device": "/dev/video0"})

tests/unit/test_websocket_server/test_server_status_aggregation.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac482e0e0>
params = {'device': '/dev/video0'}

    async def _method_get_camera_status(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Get detailed status for a specific camera device with aggregated real data.
    
        Combines data from camera discovery monitor (with provisional/confirmed capability logic),
        MediaMTX controller (stream status and metrics), and provides graceful fallbacks.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
    
        Returns:
            Dict containing comprehensive camera status per API specification:
                - device, status, name, resolution, fps, streams, metrics, capabilities
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
    
        # Initialize response with architecture defaults
        camera_status = {
            "device": device_path,
            "status": "DISCONNECTED",
            "name": f"Camera {device_path.split('video')[-1] if 'video' in device_path else 'unknown'}",
            "resolution": "1920x1080",  # Architecture default
            "fps": 30,  # Architecture default
            "streams": {},
            "metrics": {"bytes_sent": 0, "readers": 0, "uptime": 0},
            "capabilities": {"formats": [], "resolutions": []},
        }
    
        try:
            # Get camera monitor from service manager if available
            camera_monitor = None
            if self._service_manager and hasattr(self._service_manager, '_camera_monitor'):
                camera_monitor = self._service_manager._camera_monitor
            elif self._camera_monitor:
                camera_monitor = self._camera_monitor
    
            # Get MediaMTX controller from service manager if available
            mediamtx_controller = None
            if self._service_manager and hasattr(self._service_manager, '_mediamtx_controller'):
                mediamtx_controller = self._service_manager._mediamtx_controller
            elif self._mediamtx_controller:
                mediamtx_controller = self._mediamtx_controller
    
            # Get camera info from camera monitor
            if camera_monitor:
                connected_cameras = await camera_monitor.get_connected_cameras()
                camera_device = connected_cameras.get(device_path)
    
                if camera_device:
                    camera_status.update(
                        {"status": camera_device.status, "name": camera_device.name}
                    )
    
                    # Get real capability metadata with provisional/confirmed logic
                    if camera_device.status == "CONNECTED":
                        if hasattr(
                            camera_monitor, "get_effective_capability_metadata"
                        ):
                            try:
                                capability_metadata = (
                                    camera_monitor.get_effective_capability_metadata(
                                        device_path
                                    )
                                )
    
                                # Use capability-derived resolution and fps
                                camera_status.update(
                                    {
                                        "resolution": capability_metadata.get(
                                            "resolution", "1920x1080"
                                        ),
                                        "fps": capability_metadata.get("fps", 30),
                                    }
                                )
    
                                # Update capabilities with real detected data
                                if capability_metadata.get("formats"):
                                    camera_status["capabilities"]["formats"] = (
                                        capability_metadata["formats"]
                                    )
                                if capability_metadata.get("all_resolutions"):
                                    camera_status["capabilities"]["resolutions"] = (
                                        capability_metadata["all_resolutions"]
                                    )
    
                                # Log validation status for monitoring
                                validation_status = capability_metadata.get(
                                    "validation_status", "none"
                                )
                                self._logger.debug(
                                    f"Camera {device_path} using {validation_status} capability data: "
                                    f"{camera_status['resolution']}@{camera_status['fps']}fps"
                                )
    
                            except Exception as e:
                                self._logger.debug(
                                    f"Could not get capability metadata for {device_path}: {e}"
                                )
                else:
                    # Camera not found - return error
                    raise CameraNotFoundError(f"Camera device {device_path} not found")
            else:
                # Without a camera monitor, we cannot validate the device. Fail closed for correctness.
                raise CameraNotFoundError(f"Camera device {device_path} not found")
    
            # Get stream info and metrics from MediaMTX controller
            if mediamtx_controller and camera_status["status"] == "CONNECTED":
                try:
                    stream_name = self._get_stream_name_from_device_path(device_path)
                    stream_status = await mediamtx_controller.get_stream_status(
                        stream_name
                    )
    
                    if stream_status.get("status") == "active":
                        # Update stream URLs
                        camera_status["streams"] = {
                            "rtsp": f"rtsp://localhost:8554/{stream_name}",
                            "webrtc": f"webrtc://localhost:8002/{stream_name}",
                            "hls": f"http://localhost:8002/hls/{stream_name}.m3u8",
                        }
    
                        # Update metrics from MediaMTX
                        camera_status["metrics"] = {
                            "bytes_sent": stream_status.get("bytes_sent", 0),
                            "readers": stream_status.get("readers", 0),
                            "uptime": int(time.time()),  # Current uptime proxy
                        }
    
                except Exception as e:
                    self._logger.debug(
                        f"Could not get MediaMTX status for {device_path}: {e}"
                    )
    
            return camera_status
    
        except CameraNotFoundError:
            self._logger.error(f"Camera device {device_path} not found")
            raise CameraNotFoundError(f"Camera device {device_path} not found")
        except Exception as e:
            self._logger.error(f"Error getting camera status for {device_path}: {e}")
            # Return JSON-RPC error response
>           raise ValueError(f"Camera device {device_path} not found") from e
E           ValueError: Camera device /dev/video0 not found

src/websocket_server/server.py:1313: ValueError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:57 - src.websocket_server.server - ERROR - [26597fb6] Error getting camera status for /dev/video0: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'
------------------------------ Captured log call -------------------------------
ERROR    src.websocket_server.server:server.py:1311 Error getting camera status for /dev/video0: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'
___ TestServerStatusAggregation.test_get_camera_status_fallback_to_defaults ____

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac660fbb0>
params = {'device': '/dev/video0'}

    async def _method_get_camera_status(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Get detailed status for a specific camera device with aggregated real data.
    
        Combines data from camera discovery monitor (with provisional/confirmed capability logic),
        MediaMTX controller (stream status and metrics), and provides graceful fallbacks.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
    
        Returns:
            Dict containing comprehensive camera status per API specification:
                - device, status, name, resolution, fps, streams, metrics, capabilities
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
    
        # Initialize response with architecture defaults
        camera_status = {
            "device": device_path,
            "status": "DISCONNECTED",
            "name": f"Camera {device_path.split('video')[-1] if 'video' in device_path else 'unknown'}",
            "resolution": "1920x1080",  # Architecture default
            "fps": 30,  # Architecture default
            "streams": {},
            "metrics": {"bytes_sent": 0, "readers": 0, "uptime": 0},
            "capabilities": {"formats": [], "resolutions": []},
        }
    
        try:
            # Get camera monitor from service manager if available
            camera_monitor = None
>           if self._service_manager and hasattr(self._service_manager, '_camera_monitor'):
E           AttributeError: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'. Did you mean: 'set_service_manager'?

src/websocket_server/server.py:1203: AttributeError

The above exception was the direct cause of the following exception:

self = <tests.unit.test_websocket_server.test_server_status_aggregation.TestServerStatusAggregation object at 0x7faac654dc30>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac660fbb0>
mock_camera_monitor = <Mock id='140371449402208'>

    @pytest.mark.asyncio
    async def test_get_camera_status_fallback_to_defaults(
        self, server, mock_camera_monitor
    ):
        """Verify graceful fallback when capability detection unavailable."""
        # Setup camera without capability detection support
        mock_camera_device = CameraDevice(
            device="/dev/video0", name="Test Camera 0", status="CONNECTED"
        )
    
        mock_camera_monitor.get_connected_cameras.return_value = {
            "/dev/video0": mock_camera_device
        }
    
        # Remove capability detection method to simulate unavailability
        if hasattr(mock_camera_monitor, "get_effective_capability_metadata"):
            delattr(mock_camera_monitor, "get_effective_capability_metadata")
    
        # Test get_camera_status method
>       result = await server._method_get_camera_status({"device": "/dev/video0"})

tests/unit/test_websocket_server/test_server_status_aggregation.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac660fbb0>
params = {'device': '/dev/video0'}

    async def _method_get_camera_status(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Get detailed status for a specific camera device with aggregated real data.
    
        Combines data from camera discovery monitor (with provisional/confirmed capability logic),
        MediaMTX controller (stream status and metrics), and provides graceful fallbacks.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
    
        Returns:
            Dict containing comprehensive camera status per API specification:
                - device, status, name, resolution, fps, streams, metrics, capabilities
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
    
        # Initialize response with architecture defaults
        camera_status = {
            "device": device_path,
            "status": "DISCONNECTED",
            "name": f"Camera {device_path.split('video')[-1] if 'video' in device_path else 'unknown'}",
            "resolution": "1920x1080",  # Architecture default
            "fps": 30,  # Architecture default
            "streams": {},
            "metrics": {"bytes_sent": 0, "readers": 0, "uptime": 0},
            "capabilities": {"formats": [], "resolutions": []},
        }
    
        try:
            # Get camera monitor from service manager if available
            camera_monitor = None
            if self._service_manager and hasattr(self._service_manager, '_camera_monitor'):
                camera_monitor = self._service_manager._camera_monitor
            elif self._camera_monitor:
                camera_monitor = self._camera_monitor
    
            # Get MediaMTX controller from service manager if available
            mediamtx_controller = None
            if self._service_manager and hasattr(self._service_manager, '_mediamtx_controller'):
                mediamtx_controller = self._service_manager._mediamtx_controller
            elif self._mediamtx_controller:
                mediamtx_controller = self._mediamtx_controller
    
            # Get camera info from camera monitor
            if camera_monitor:
                connected_cameras = await camera_monitor.get_connected_cameras()
                camera_device = connected_cameras.get(device_path)
    
                if camera_device:
                    camera_status.update(
                        {"status": camera_device.status, "name": camera_device.name}
                    )
    
                    # Get real capability metadata with provisional/confirmed logic
                    if camera_device.status == "CONNECTED":
                        if hasattr(
                            camera_monitor, "get_effective_capability_metadata"
                        ):
                            try:
                                capability_metadata = (
                                    camera_monitor.get_effective_capability_metadata(
                                        device_path
                                    )
                                )
    
                                # Use capability-derived resolution and fps
                                camera_status.update(
                                    {
                                        "resolution": capability_metadata.get(
                                            "resolution", "1920x1080"
                                        ),
                                        "fps": capability_metadata.get("fps", 30),
                                    }
                                )
    
                                # Update capabilities with real detected data
                                if capability_metadata.get("formats"):
                                    camera_status["capabilities"]["formats"] = (
                                        capability_metadata["formats"]
                                    )
                                if capability_metadata.get("all_resolutions"):
                                    camera_status["capabilities"]["resolutions"] = (
                                        capability_metadata["all_resolutions"]
                                    )
    
                                # Log validation status for monitoring
                                validation_status = capability_metadata.get(
                                    "validation_status", "none"
                                )
                                self._logger.debug(
                                    f"Camera {device_path} using {validation_status} capability data: "
                                    f"{camera_status['resolution']}@{camera_status['fps']}fps"
                                )
    
                            except Exception as e:
                                self._logger.debug(
                                    f"Could not get capability metadata for {device_path}: {e}"
                                )
                else:
                    # Camera not found - return error
                    raise CameraNotFoundError(f"Camera device {device_path} not found")
            else:
                # Without a camera monitor, we cannot validate the device. Fail closed for correctness.
                raise CameraNotFoundError(f"Camera device {device_path} not found")
    
            # Get stream info and metrics from MediaMTX controller
            if mediamtx_controller and camera_status["status"] == "CONNECTED":
                try:
                    stream_name = self._get_stream_name_from_device_path(device_path)
                    stream_status = await mediamtx_controller.get_stream_status(
                        stream_name
                    )
    
                    if stream_status.get("status") == "active":
                        # Update stream URLs
                        camera_status["streams"] = {
                            "rtsp": f"rtsp://localhost:8554/{stream_name}",
                            "webrtc": f"webrtc://localhost:8002/{stream_name}",
                            "hls": f"http://localhost:8002/hls/{stream_name}.m3u8",
                        }
    
                        # Update metrics from MediaMTX
                        camera_status["metrics"] = {
                            "bytes_sent": stream_status.get("bytes_sent", 0),
                            "readers": stream_status.get("readers", 0),
                            "uptime": int(time.time()),  # Current uptime proxy
                        }
    
                except Exception as e:
                    self._logger.debug(
                        f"Could not get MediaMTX status for {device_path}: {e}"
                    )
    
            return camera_status
    
        except CameraNotFoundError:
            self._logger.error(f"Camera device {device_path} not found")
            raise CameraNotFoundError(f"Camera device {device_path} not found")
        except Exception as e:
            self._logger.error(f"Error getting camera status for {device_path}: {e}")
            # Return JSON-RPC error response
>           raise ValueError(f"Camera device {device_path} not found") from e
E           ValueError: Camera device /dev/video0 not found

src/websocket_server/server.py:1313: ValueError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:57 - src.websocket_server.server - ERROR - [26597fb6] Error getting camera status for /dev/video0: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'
------------------------------ Captured log call -------------------------------
ERROR    src.websocket_server.server:server.py:1311 Error getting camera status for /dev/video0: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'
___ TestServerStatusAggregation.test_get_camera_list_capability_integration ____

self = <tests.unit.test_websocket_server.test_server_status_aggregation.TestServerStatusAggregation object at 0x7faac654e920>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac46842e0>
mock_camera_monitor = <Mock id='140371416345680'>
mock_mediamtx_controller = <Mock id='140371416336320'>

    @pytest.mark.asyncio
    async def test_get_camera_list_capability_integration(
        self, server, mock_camera_monitor, mock_mediamtx_controller
    ):
        """Verify get_camera_list uses real capability data for resolution/fps."""
        # Setup multiple connected cameras with capability data
        mock_cameras = {
>           "/dev/video0": CameraDevice("/dev/video0", "Camera 0", "CONNECTED"),
            "/dev/video1": CameraDevice("/dev/video1", "Camera 1", "CONNECTED"),
            "/dev/video2": CameraDevice("/dev/video2", "Camera 2", "DISCONNECTED"),
        }
E       TypeError: CameraDevice.__init__() takes from 1 to 3 positional arguments but 4 were given

tests/unit/test_websocket_server/test_server_status_aggregation.py:158: TypeError
_ TestServerStatusAggregation.test_get_camera_status_provisional_vs_confirmed_logic _

self = <tests.unit.test_websocket_server.test_server_status_aggregation.TestServerStatusAggregation object at 0x7faac654f910>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4a93df0>
mock_camera_monitor = <Mock id='140371416129616'>

    @pytest.mark.asyncio
    async def test_get_camera_status_provisional_vs_confirmed_logic(
        self, server, mock_camera_monitor
    ):
        """Test that provisional and confirmed capability data are handled correctly."""
        # Setup camera with provisional capability data
>       mock_camera_device = CameraDevice("/dev/video0", "Test Camera", "CONNECTED")
E       TypeError: CameraDevice.__init__() takes from 1 to 3 positional arguments but 4 were given

tests/unit/test_websocket_server/test_server_status_aggregation.py:225: TypeError
_ TestServerStatusAggregation.test_graceful_degradation_missing_camera_monitor _

self = <tests.unit.test_websocket_server.test_server_status_aggregation.TestServerStatusAggregation object at 0x7faac654ee90>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4bd57e0>

    @pytest.mark.asyncio
    async def test_graceful_degradation_missing_camera_monitor(self, server):
        """Verify methods handle missing camera_monitor gracefully."""
        # Remove camera monitor to simulate unavailability
        server._camera_monitor = None
    
        # Test get_camera_list with missing camera monitor
>       result = await server._method_get_camera_list()

tests/unit/test_websocket_server/test_server_status_aggregation.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4bd57e0>
params = None

    async def _method_get_camera_list(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Get list of all discovered cameras with their current status and aggregated metadata.
    
        Integrates real data from camera discovery monitor (with provisional/confirmed capability logic)
        and MediaMTX controller. Returns architecture-compliant response structure.
    
        Args:
            params: Method parameters (unused)
    
        Returns:
            Object with camera list and metadata per API specification
        """
        # Get camera monitor from service manager if available
        camera_monitor = None
>       if self._service_manager and hasattr(self._service_manager, '_camera_monitor'):
E       AttributeError: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'. Did you mean: 'set_service_manager'?

src/websocket_server/server.py:1065: AttributeError
_ TestServerStatusAggregation.test_graceful_degradation_missing_mediamtx_controller _

self = <tests.unit.test_websocket_server.test_server_status_aggregation.TestServerStatusAggregation object at 0x7faac6805450>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4a82470>
mock_camera_monitor = <Mock id='140371420513808'>

    @pytest.mark.asyncio
    async def test_graceful_degradation_missing_mediamtx_controller(
        self, server, mock_camera_monitor
    ):
        """Verify methods handle missing MediaMTX controller gracefully."""
        # Setup camera monitor but remove MediaMTX controller
>       mock_camera_device = CameraDevice("/dev/video0", "Test Camera", "CONNECTED")
E       TypeError: CameraDevice.__init__() takes from 1 to 3 positional arguments but 4 were given

tests/unit/test_websocket_server/test_server_status_aggregation.py:284: TypeError
________ TestServerStatusAggregation.test_camera_status_error_handling _________

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4c05060>
params = {'device': '/dev/video0'}

    async def _method_get_camera_status(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Get detailed status for a specific camera device with aggregated real data.
    
        Combines data from camera discovery monitor (with provisional/confirmed capability logic),
        MediaMTX controller (stream status and metrics), and provides graceful fallbacks.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
    
        Returns:
            Dict containing comprehensive camera status per API specification:
                - device, status, name, resolution, fps, streams, metrics, capabilities
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
    
        # Initialize response with architecture defaults
        camera_status = {
            "device": device_path,
            "status": "DISCONNECTED",
            "name": f"Camera {device_path.split('video')[-1] if 'video' in device_path else 'unknown'}",
            "resolution": "1920x1080",  # Architecture default
            "fps": 30,  # Architecture default
            "streams": {},
            "metrics": {"bytes_sent": 0, "readers": 0, "uptime": 0},
            "capabilities": {"formats": [], "resolutions": []},
        }
    
        try:
            # Get camera monitor from service manager if available
            camera_monitor = None
>           if self._service_manager and hasattr(self._service_manager, '_camera_monitor'):
E           AttributeError: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'. Did you mean: 'set_service_manager'?

src/websocket_server/server.py:1203: AttributeError

The above exception was the direct cause of the following exception:

self = <tests.unit.test_websocket_server.test_server_status_aggregation.TestServerStatusAggregation object at 0x7faac65c3a60>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4c05060>
mock_camera_monitor = <Mock id='140371418085216'>

    @pytest.mark.asyncio
    async def test_camera_status_error_handling(self, server, mock_camera_monitor):
        """Test error handling in camera status aggregation."""
        # Setup camera monitor to raise exception
        mock_camera_monitor.get_connected_cameras.side_effect = Exception(
            "Camera monitor error"
        )
    
        # Test get_camera_status with exception
>       result = await server._method_get_camera_status({"device": "/dev/video0"})

tests/unit/test_websocket_server/test_server_status_aggregation.py:308: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac4c05060>
params = {'device': '/dev/video0'}

    async def _method_get_camera_status(
        self, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Get detailed status for a specific camera device with aggregated real data.
    
        Combines data from camera discovery monitor (with provisional/confirmed capability logic),
        MediaMTX controller (stream status and metrics), and provides graceful fallbacks.
    
        Args:
            params: Method parameters containing:
                - device (str): Camera device path
    
        Returns:
            Dict containing comprehensive camera status per API specification:
                - device, status, name, resolution, fps, streams, metrics, capabilities
        """
        if not params or "device" not in params:
            raise ValueError("device parameter is required")
    
        device_path = params["device"]
    
        # Initialize response with architecture defaults
        camera_status = {
            "device": device_path,
            "status": "DISCONNECTED",
            "name": f"Camera {device_path.split('video')[-1] if 'video' in device_path else 'unknown'}",
            "resolution": "1920x1080",  # Architecture default
            "fps": 30,  # Architecture default
            "streams": {},
            "metrics": {"bytes_sent": 0, "readers": 0, "uptime": 0},
            "capabilities": {"formats": [], "resolutions": []},
        }
    
        try:
            # Get camera monitor from service manager if available
            camera_monitor = None
            if self._service_manager and hasattr(self._service_manager, '_camera_monitor'):
                camera_monitor = self._service_manager._camera_monitor
            elif self._camera_monitor:
                camera_monitor = self._camera_monitor
    
            # Get MediaMTX controller from service manager if available
            mediamtx_controller = None
            if self._service_manager and hasattr(self._service_manager, '_mediamtx_controller'):
                mediamtx_controller = self._service_manager._mediamtx_controller
            elif self._mediamtx_controller:
                mediamtx_controller = self._mediamtx_controller
    
            # Get camera info from camera monitor
            if camera_monitor:
                connected_cameras = await camera_monitor.get_connected_cameras()
                camera_device = connected_cameras.get(device_path)
    
                if camera_device:
                    camera_status.update(
                        {"status": camera_device.status, "name": camera_device.name}
                    )
    
                    # Get real capability metadata with provisional/confirmed logic
                    if camera_device.status == "CONNECTED":
                        if hasattr(
                            camera_monitor, "get_effective_capability_metadata"
                        ):
                            try:
                                capability_metadata = (
                                    camera_monitor.get_effective_capability_metadata(
                                        device_path
                                    )
                                )
    
                                # Use capability-derived resolution and fps
                                camera_status.update(
                                    {
                                        "resolution": capability_metadata.get(
                                            "resolution", "1920x1080"
                                        ),
                                        "fps": capability_metadata.get("fps", 30),
                                    }
                                )
    
                                # Update capabilities with real detected data
                                if capability_metadata.get("formats"):
                                    camera_status["capabilities"]["formats"] = (
                                        capability_metadata["formats"]
                                    )
                                if capability_metadata.get("all_resolutions"):
                                    camera_status["capabilities"]["resolutions"] = (
                                        capability_metadata["all_resolutions"]
                                    )
    
                                # Log validation status for monitoring
                                validation_status = capability_metadata.get(
                                    "validation_status", "none"
                                )
                                self._logger.debug(
                                    f"Camera {device_path} using {validation_status} capability data: "
                                    f"{camera_status['resolution']}@{camera_status['fps']}fps"
                                )
    
                            except Exception as e:
                                self._logger.debug(
                                    f"Could not get capability metadata for {device_path}: {e}"
                                )
                else:
                    # Camera not found - return error
                    raise CameraNotFoundError(f"Camera device {device_path} not found")
            else:
                # Without a camera monitor, we cannot validate the device. Fail closed for correctness.
                raise CameraNotFoundError(f"Camera device {device_path} not found")
    
            # Get stream info and metrics from MediaMTX controller
            if mediamtx_controller and camera_status["status"] == "CONNECTED":
                try:
                    stream_name = self._get_stream_name_from_device_path(device_path)
                    stream_status = await mediamtx_controller.get_stream_status(
                        stream_name
                    )
    
                    if stream_status.get("status") == "active":
                        # Update stream URLs
                        camera_status["streams"] = {
                            "rtsp": f"rtsp://localhost:8554/{stream_name}",
                            "webrtc": f"webrtc://localhost:8002/{stream_name}",
                            "hls": f"http://localhost:8002/hls/{stream_name}.m3u8",
                        }
    
                        # Update metrics from MediaMTX
                        camera_status["metrics"] = {
                            "bytes_sent": stream_status.get("bytes_sent", 0),
                            "readers": stream_status.get("readers", 0),
                            "uptime": int(time.time()),  # Current uptime proxy
                        }
    
                except Exception as e:
                    self._logger.debug(
                        f"Could not get MediaMTX status for {device_path}: {e}"
                    )
    
            return camera_status
    
        except CameraNotFoundError:
            self._logger.error(f"Camera device {device_path} not found")
            raise CameraNotFoundError(f"Camera device {device_path} not found")
        except Exception as e:
            self._logger.error(f"Error getting camera status for {device_path}: {e}")
            # Return JSON-RPC error response
>           raise ValueError(f"Camera device {device_path} not found") from e
E           ValueError: Camera device /dev/video0 not found

src/websocket_server/server.py:1313: ValueError
----------------------------- Captured stdout call -----------------------------
2025-08-10 12:09:58 - src.websocket_server.server - ERROR - [26597fb6] Error getting camera status for /dev/video0: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'
------------------------------ Captured log call -------------------------------
ERROR    src.websocket_server.server:server.py:1311 Error getting camera status for /dev/video0: 'WebSocketJsonRpcServer' object has no attribute '_service_manager'
___ TestServerStatusAggregation.test_stream_name_generation_from_device_path ___

self = <tests.unit.test_websocket_server.test_server_status_aggregation.TestServerStatusAggregation object at 0x7faac65c0cd0>
server = <src.websocket_server.server.WebSocketJsonRpcServer object at 0x7faac470f8b0>

    @pytest.mark.asyncio
    async def test_stream_name_generation_from_device_path(self, server):
        """Test stream name generation for various device path formats."""
        # Test standard device paths
        assert server._get_stream_name_from_device_path("/dev/video0") == "camera0"
        assert server._get_stream_name_from_device_path("/dev/video15") == "camera15"
    
        # Test non-standard paths
        stream_name = server._get_stream_name_from_device_path("/custom/device/path")
        assert stream_name.startswith("camera_")  # Should generate hash-based name
    
        # Test error handling
        stream_name = server._get_stream_name_from_device_path("")
>       assert stream_name == "camera_unknown"
E       AssertionError: assert 'camera_0' == 'camera_unknown'
E         
E         - camera_unknown
E         + camera_0

tests/unit/test_websocket_server/test_server_status_aggregation.py:334: AssertionError
=============================== warnings summary ===============================
tests/unit/test_mediamtx_wrapper/test_controller_configuration.py::TestConfigurationValidation::test_configuration_update_api_failure_safe_fallback
tests/unit/test_mediamtx_wrapper/test_controller_configuration.py::TestConfigurationValidation::test_configuration_update_network_error_handling
tests/unit/test_mediamtx_wrapper/test_controller_configuration.py::TestConfigurationValidation::test_configuration_validation_valid_config_success
tests/unit/test_mediamtx_wrapper/test_controller_configuration.py::TestConfigurationValidation::test_configuration_validation_correlation_id_logging
  /home/dts/CameraRecorder/mediamtx-camera-service/src/mediamtx_wrapper/controller.py:1316: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited
    async with self._session.post(
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_duration_calculation_precision
tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_missing_file_handling
tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_file_permission_error
tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_session_management
tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_api_failure_preserves_session
tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_duplicate_start_error
tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_format_validation
  /home/dts/CameraRecorder/mediamtx-camera-service/src/mediamtx_wrapper/controller.py:611: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited
    async with self._session.post(
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_create_stream_success
tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_create_stream_conflict_409_idempotent
tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_create_stream_api_error_with_context
tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_create_stream_network_error
tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_stream_config_with_recording
  /home/dts/CameraRecorder/mediamtx-camera-service/src/mediamtx_wrapper/controller.py:407: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited
    async with self._session.post(
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_delete_stream_success
tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_delete_stream_idempotent_404
tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_delete_stream_api_error
tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_delete_stream_network_error
  /home/dts/CameraRecorder/mediamtx-camera-service/src/mediamtx_wrapper/controller.py:491: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited
    async with self._session.post(
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_capability_parsing.py::TestCapabilityParsingVariations::test_capability_parsing_malformed_v4l2_outputs
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py::TestCapabilityParsingVariations::test_capability_parsing_malformed_v4l2_outputs
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py::TestUdevEventProcessingAndRaceConditions::test_udev_event_filtering_comprehensive
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py::TestUdevEventProcessingAndRaceConditions::test_udev_race_condition_simulation
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py::TestUdevEventProcessingAndRaceConditions::test_udev_change_event_status_detection
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py::TestPollingFallbackBehavior::test_polling_failure_backoff_with_jitter
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_comprehensive.py::TestIntegrationAndLifecycle::test_end_to_end_device_workflow
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py::TestUdevEventProcessing::test_udev_add_event_processing
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py::TestUdevEventProcessing::test_udev_event_race_conditions
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py::TestUdevEventProcessing::test_invalid_device_node_handling
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py::TestUdevEventProcessing::test_device_range_filtering
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py::TestPollingFallback::test_polling_fallback_when_udev_stale
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py::TestPollingFallback::test_adaptive_polling_interval_adjustment
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py::TestPollingFallback::test_polling_failure_recovery
FAILED tests/unit/test_camera_discovery/test_hybrid_monitor_udev_fallback.py::TestPollingFallback::test_polling_only_mode_fallback
FAILED tests/unit/test_camera_discovery/test_udev_processing.py::test_udev_event_filtering
FAILED tests/unit/test_camera_service/test_logging_config.py::TestJsonFormatter::test_json_formatter_with_exception
FAILED tests/unit/test_camera_service/test_logging_config.py::TestConsoleFormatter::test_console_formatter_with_correlation_id
FAILED tests/unit/test_configuration_validation.py::TestConfigurationSchemaValidation::test_service_manager_config_instantiation
FAILED tests/unit/test_configuration_validation.py::TestConfigurationSchemaValidation::test_config_default_values
FAILED tests/unit/test_configuration_validation.py::TestConfigurationSchemaValidation::test_config_serialization_compatibility
FAILED tests/unit/test_configuration_validation.py::TestConfigurationFileValidation::test_default_yaml_config_compatibility
FAILED tests/unit/test_mediamtx_wrapper/test_controller_configuration.py::TestConfigurationValidation::test_configuration_validation_pattern_matching
FAILED tests/unit/test_mediamtx_wrapper/test_controller_configuration.py::TestConfigurationValidation::test_configuration_update_api_failure_safe_fallback
FAILED tests/unit/test_mediamtx_wrapper/test_controller_configuration.py::TestConfigurationValidation::test_configuration_update_network_error_handling
FAILED tests/unit/test_mediamtx_wrapper/test_controller_configuration.py::TestConfigurationValidation::test_configuration_validation_valid_config_success
FAILED tests/unit/test_mediamtx_wrapper/test_controller_configuration.py::TestConfigurationValidation::test_configuration_validation_correlation_id_logging
FAILED tests/unit/test_mediamtx_wrapper/test_controller_health_monitoring.py::TestHealthMonitoring::test_circuit_breaker_recovery_confirmation_threshold
FAILED tests/unit/test_mediamtx_wrapper/test_controller_health_monitoring.py::TestHealthMonitoring::test_recovery_confirmation_reset_on_failure
FAILED tests/unit/test_mediamtx_wrapper/test_controller_health_monitoring.py::TestHealthMonitoring::test_health_state_transition_logging
FAILED tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_duration_calculation_precision
FAILED tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_missing_file_handling
FAILED tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_file_permission_error
FAILED tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_session_management
FAILED tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_api_failure_preserves_session
FAILED tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_duplicate_start_error
FAILED tests/unit/test_mediamtx_wrapper/test_controller_recording_duration.py::TestRecordingDuration::test_recording_format_validation
FAILED tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py::TestSnapshotCapture::test_snapshot_process_cleanup_on_timeout
FAILED tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py::TestSnapshotCapture::test_snapshot_file_size_error_handling
FAILED tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py::TestSnapshotCapture::test_snapshot_ffmpeg_nonzero_exit_code
FAILED tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py::TestSnapshotCapture::test_snapshot_success_with_accurate_metadata
FAILED tests/unit/test_mediamtx_wrapper/test_controller_snapshot_capture.py::TestSnapshotCapture::test_snapshot_process_creation_timeout
FAILED tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_create_stream_success
FAILED tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_create_stream_conflict_409_idempotent
FAILED tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_create_stream_api_error_with_context
FAILED tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_create_stream_network_error
FAILED tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_delete_stream_success
FAILED tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_delete_stream_idempotent_404
FAILED tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_delete_stream_api_error
FAILED tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_delete_stream_network_error
FAILED tests/unit/test_mediamtx_wrapper/test_controller_stream_operations.py::TestStreamOperations::test_stream_config_with_recording
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py::TestHealthMonitorBackoffJitter::test_exponential_backoff_calculation
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py::TestHealthMonitorBackoffJitter::test_backoff_with_jitter
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py::TestHealthMonitorBackoffJitter::test_backoff_maximum_cap_enforcement
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py::TestHealthMonitorBackoffJitter::test_backoff_reset_on_success
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py::TestHealthMonitorBackoffJitter::test_circuit_breaker_backoff_interaction
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_backoff_jitter.py::TestHealthMonitorBackoffJitter::test_deterministic_backoff_with_no_jitter
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py::TestHealthMonitorFlapping::test_circuit_breaker_activation_threshold
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py::TestHealthMonitorFlapping::test_flapping_resistance_during_recovery
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py::TestHealthMonitorFlapping::test_rapid_flapping_scenario
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py::TestHealthMonitorFlapping::test_multiple_circuit_breaker_cycles
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py::TestHealthMonitorFlapping::test_recovery_confirmation_boundary_conditions
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_circuit_breaker_flapping.py::TestHealthMonitorFlapping::test_no_premature_circuit_breaker_reset
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py::TestHealthMonitorRecoveryConfirmation::test_exact_consecutive_success_requirement
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py::TestHealthMonitorRecoveryConfirmation::test_insufficient_consecutive_successes
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py::TestHealthMonitorRecoveryConfirmation::test_failure_resets_confirmation_progress
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py::TestHealthMonitorRecoveryConfirmation::test_circuit_breaker_timeout_behavior
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py::TestHealthMonitorRecoveryConfirmation::test_recovery_state_tracking
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py::TestHealthMonitorRecoveryConfirmation::test_configurable_confirmation_threshold
FAILED tests/unit/test_mediamtx_wrapper/test_health_monitor_recovery_confirmation.py::TestHealthMonitorRecoveryConfirmation::test_partial_recovery_logging
FAILED tests/unit/test_websocket_server/test_server_method_handlers.py::TestServerMethodHandlers::test_take_snapshot_parameter_handling
FAILED tests/unit/test_websocket_server/test_server_method_handlers.py::TestServerMethodHandlers::test_recording_methods_parameter_handling
FAILED tests/unit/test_websocket_server/test_server_method_handlers.py::TestServerMethodHandlers::test_method_error_handling_no_mediamtx
FAILED tests/unit/test_websocket_server/test_server_method_handlers.py::TestServerMethodHandlers::test_stream_name_extraction
FAILED tests/unit/test_websocket_server/test_server_method_handlers.py::TestServerMethodHandlers::test_method_exception_handling
FAILED tests/unit/test_websocket_server/test_server_method_handlers.py::TestServerMethodHandlers::test_method_handlers_with_mock_dependencies
FAILED tests/unit/test_websocket_server/test_server_notifications.py::TestServerNotifications::test_send_notification_to_specific_client
FAILED tests/unit/test_websocket_server/test_server_status_aggregation.py::TestServerStatusAggregation::test_get_camera_status_uses_real_capability_data
FAILED tests/unit/test_websocket_server/test_server_status_aggregation.py::TestServerStatusAggregation::test_get_camera_status_fallback_to_defaults
FAILED tests/unit/test_websocket_server/test_server_status_aggregation.py::TestServerStatusAggregation::test_get_camera_list_capability_integration
FAILED tests/unit/test_websocket_server/test_server_status_aggregation.py::TestServerStatusAggregation::test_get_camera_status_provisional_vs_confirmed_logic
FAILED tests/unit/test_websocket_server/test_server_status_aggregation.py::TestServerStatusAggregation::test_graceful_degradation_missing_camera_monitor
FAILED tests/unit/test_websocket_server/test_server_status_aggregation.py::TestServerStatusAggregation::test_graceful_degradation_missing_mediamtx_controller
FAILED tests/unit/test_websocket_server/test_server_status_aggregation.py::TestServerStatusAggregation::test_camera_status_error_handling
FAILED tests/unit/test_websocket_server/test_server_status_aggregation.py::TestServerStatusAggregation::test_stream_name_generation_from_device_path
================= 85 failed, 237 passed, 20 warnings in 28.37s =================
